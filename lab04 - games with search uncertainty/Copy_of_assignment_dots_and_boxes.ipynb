{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HhWD12pIBvA"
      },
      "source": [
        "# Adversarial Search: Playing Dots and Boxes\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undegraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play the game Dots and Boxes:\n",
        "\n",
        "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
        "\n",
        "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgHaUbhoIBvC"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem associated with this game:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model\n",
        "* Test for the terminal state\n",
        "* Utility for terminal states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7kBSiFIBvD"
      },
      "outputs": [],
      "source": [
        "def initial_state(size=2):\n",
        "  # trả về dictionary\n",
        "    return {\n",
        "        \"size\": size,\n",
        "        #cac đường kẽ đã dc vẽ\n",
        "        \"lines\": set(),\n",
        "        # lưu điểm 2 ng chs ban đầu\n",
        "        \"scores\": {1: 0, 2: 0},\n",
        "        \"player\": 1\n",
        "    }\n",
        "\n",
        "def actions(state):\n",
        "    n = state[\"size\"]\n",
        "    all_edges = set()\n",
        "    # Tạo tất cả các cạnh hợp lệ (ngang và dọc)\n",
        "    for x in range(n+1):\n",
        "        for y in range(n+1):\n",
        "            if x < n:\n",
        "                all_edges.add(((x, y), (x+1, y)))  # dọc\n",
        "            if y < n:\n",
        "                all_edges.add(((x, y), (x, y+1)))  # ngang\n",
        "    return list(all_edges - state[\"lines\"])\n",
        "\n",
        "def check_completed_boxes(state, action):\n",
        "    # Hàm kiểm tra số ô vuông hoàn thành\n",
        "    # (có thể tạm giả định trả 0 để định nghĩa mô hình cơ bản)\n",
        "    return 0\n",
        "\n",
        "def transition_model(state, action):\n",
        "  #chuyển đồi trạng thái sau mỗi hành động\n",
        "    new_state = {\n",
        "        \"size\": state[\"size\"],\n",
        "        \"lines\": state[\"lines\"].copy(),\n",
        "        \"scores\": state[\"scores\"].copy(),\n",
        "        \"player\": state[\"player\"]\n",
        "    }\n",
        "    new_state[\"lines\"].add(action)\n",
        "    completed_boxes = check_completed_boxes(new_state, action)\n",
        "    #trạng thái hoàn thành 1 ô\n",
        "    if completed_boxes > 0:\n",
        "        new_state[\"scores\"][state[\"player\"]] += completed_boxes\n",
        "    else:\n",
        "      #Lượt chơi được chuyển cho đối thủ\n",
        "        new_state[\"player\"] = 1 if state[\"player\"] == 2 else 2\n",
        "    return new_state\n",
        "\n",
        "#Nó kiểm tra xem trò chơi đã kết thúc hay chưa\n",
        "def is_terminal(state):\n",
        "    total_edges = state[\"size\"] * (state[\"size\"] + 1) * 2\n",
        "    return len(state[\"lines\"]) == total_edges\n",
        "# trả về hiệu số của 2 ng chs\n",
        "def utility(state, player):\n",
        "    return state[\"scores\"][player] - state[\"scores\"][3 - player]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UU7zKGLIBvE"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jBcUavIBvF",
        "outputId": "7643fa72-3a1c-4eaf-e11f-a94127a6deb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n=1: E=4, upper bound states (with player) = 32\n",
            "n=2: E=12, upper bound states (with player) = 8,192\n",
            "n=3: E=24, upper bound states (with player) = 33,554,432\n",
            "n=4: E=40, upper bound states (with player) = 2,199,023,255,552\n",
            "n=5: E=60, upper bound states (with player) = 2,305,843,009,213,693,952\n",
            "n=6: E=84, upper bound states (with player) = 38,685,626,227,668,133,590,597,632\n"
          ]
        }
      ],
      "source": [
        "def edges_count(n):\n",
        "    # n = số ô theo hàng/ cột\n",
        "    return 2 * n * (n + 1)\n",
        "#Tính ước lượng trên (upper bound) cho số lượng trạng thái có thể có của trò chơi\n",
        "def state_space_upper_bound(n, include_player=True):\n",
        "    E = edges_count(n)\n",
        "    if include_player:\n",
        "        return 2 ** (E + 1)\n",
        "    else:\n",
        "        return 2 ** E\n",
        "\n",
        "for n in [1,2,3,4,5,6]:\n",
        "    E = edges_count(n)\n",
        "    ub = state_space_upper_bound(n)\n",
        "    print(f\"n={n}: E={E}, upper bound states (with player) = {ub:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQEhq-5vB5v3"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Số đường tăng theo công thức bậc hai E = 2·n·(n+1), số trạng thái tăng theo hàm mũ 2^(E+1), với n nhỏ (1-2) có thể giải toàn bộ, n=3 đã ~33 triệu trạng thái, n≥4 lên đến hàng tỷ tỉ, cho thấy việc duyệt toàn bộ không gian trạng thái là không khả thi, cần cắt tỉa, heuristic hoặc phương pháp xấp xỉ; việc tính thêm lượt người chơi tăng số trạng thái gấp đôi nhưng vẫn giữ xu hướng tăng mũ, giải thích tại sao thuật toán Minimax cần lưu cả thông tin lượt đi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA4l2qyvIBvF"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_tGWyo9IBvG",
        "outputId": "dbc85fb1-b899-4aac-a226-5e9aca83062f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bàn 1x1: Có tổng cộng 4 cạnh có thể nối.\n",
            "Ước lượng chính xác theo giai thừa (E!) ≈ 2.400e+01\n",
            "Ước lượng gần đúng (b^d) ≈ 1.600e+01\n",
            "\n",
            "Bàn 2x2: Có tổng cộng 12 cạnh có thể nối.\n",
            "Ước lượng chính xác theo giai thừa (E!) ≈ 4.790e+08\n",
            "Ước lượng gần đúng (b^d) ≈ 2.177e+09\n",
            "\n",
            "Bàn 3x3: Có tổng cộng 24 cạnh có thể nối.\n",
            "Ước lượng chính xác theo giai thừa (E!) ≈ 6.204e+23\n",
            "Ước lượng gần đúng (b^d) ≈ 7.950e+25\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def game_tree_size_factorial(n):\n",
        "    E = edges_count(n)\n",
        "    return math.factorial(E)\n",
        "\n",
        "def game_tree_estimate_b_to_d(n):\n",
        "    E = edges_count(n)\n",
        "    b = E / 2  # hệ số phân nhánh trung bình\n",
        "    return b ** E\n",
        "\n",
        "for n in [1, 2, 3]:\n",
        "    E = edges_count(n)\n",
        "    print(f\"Bàn {n}x{n}: Có tổng cộng {E} cạnh có thể nối.\")\n",
        "    print(f\"Ước lượng chính xác theo giai thừa (E!) ≈ {game_tree_size_factorial(n):.3e}\")\n",
        "    print(f\"Ước lượng gần đúng (b^d) ≈ {game_tree_estimate_b_to_d(n):.3e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV1VCJB8Dede"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Cả hai phương pháp ước lượng số lượng cây trò chơi đều tăng rất nhanh theo số cạnh E; ước lượng chính xác theo giai thừa (E!) cho thấy số trạng thái tăng cực nhanh, trong khi ước lượng gần đúng theo b^d với b=E/2 thường cho giá trị lớn hơn một chút, nhưng cùng xu hướng tăng mũ, cho thấy ngay với bảng 3x3 số lượng trạng thái đã lên tới khoảng 10^24–10^25, nhấn mạnh rằng việc duyệt toàn bộ cây trò chơi là không khả thi và cần dùng các phương pháp cắt tỉa, heuristic hoặc xấp xỉ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itJjwkVTIBvG"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [30 point]\n",
        "\n",
        "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary with components representing the board size, the lines and the boxes on the board.\n",
        "\n",
        "**Important:** Everybody needs to use the same representation so we can let agents play against each other later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTNjTgGLIBvH",
        "outputId": "aa0f6a91-3714-49b7-fe47-d7eba6995df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'size': (4, 4),\n",
              " 'lines': {('h', 1, 1): True, ('v', 1, 1): True},\n",
              " 'boxes': dict}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "board = {\n",
        "    'size': (4, 4),  ### number of rows and columns of dots\n",
        "    'lines': dict(), ### keys are the set of drawn lines\n",
        "    'boxes': dict    ### keys are the boxes and the value is the player who completed each box\n",
        "}\n",
        "\n",
        "def draw_line(board, orientation, row, col):\n",
        "    \"\"\"\n",
        "    Place a line on an exiting board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board: dict\n",
        "        the board\n",
        "    orientation: str\n",
        "        either 'h' or 'v' for horizontal or vertical\n",
        "    row, col: int\n",
        "        index of the starting dot for the line (starting with 0)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if orientation not in ['h', 'v']:\n",
        "        return False\n",
        "\n",
        "    if row < 0 or col < 0:\n",
        "        return False\n",
        "\n",
        "    if row >= board['size'][0] + (orientation == 'v') or col >= board['size'][1] + (orientation == 'h'):\n",
        "        return False\n",
        "\n",
        "    if (orientation, row, col) in board['lines']:\n",
        "        return False\n",
        "\n",
        "    board[\"lines\"][(orientation, row, col)] = True\n",
        "    return True\n",
        "\n",
        "\n",
        "print(draw_line(board, \"h\", 1, 1))\n",
        "print(draw_line(board, \"v\", 1, 1))\n",
        "\n",
        "# this should not work\n",
        "print(draw_line(board, \"h\", 1, 1))\n",
        "\n",
        "board"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCzNKBJ_IBvI"
      },
      "source": [
        "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5tYhNcQIBvI",
        "outputId": "53162770-a9b7-4ace-a38c-8a620312377d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "●──●  ●  ●  \n",
            "│ B │           \n",
            "●──●  ●  ●  \n",
            "                \n",
            "●  ●  ●  ●  \n",
            "                \n",
            "●  ●  ●  ●  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def display_board(board):\n",
        "    \"\"\"\n",
        "    Hiển thị bàn chơi Dots and Boxes bằng ký tự ASCII.\n",
        "    Các điểm là ●, các đường ngang là ──, đường dọc là │.\n",
        "    \"\"\"\n",
        "\n",
        "    rows, cols = board['size']\n",
        "    lines = board['lines']\n",
        "    boxes = board['boxes']\n",
        "\n",
        "    for r in range(rows):\n",
        "        # --- In hàng đường ngang ---\n",
        "        line_row = \"\"\n",
        "        for c in range(cols):\n",
        "            line_row += \"●\"\n",
        "            if ('h', r, c) in lines:\n",
        "                line_row += \"──\"\n",
        "            else:\n",
        "                line_row += \"  \"\n",
        "        print(line_row)\n",
        "\n",
        "        # --- In hàng ô và đường dọc ---\n",
        "        if r < rows - 1:\n",
        "            box_row = \"\"\n",
        "            for c in range(cols):\n",
        "                if ('v', r, c) in lines:\n",
        "                    box_row += \"│\"\n",
        "                else:\n",
        "                    box_row += \" \"\n",
        "                # hiển thị người chơi nếu ô đã hoàn thành\n",
        "                if (r, c) in boxes:\n",
        "                    box_row += f\" {boxes[(r, c)]} \"\n",
        "                else:\n",
        "                    box_row += \"   \"\n",
        "            print(box_row)\n",
        "    print()  # dòng trống cuối\n",
        "\n",
        "\n",
        "# --- Thử nghiệm ---\n",
        "board = {\n",
        "    'size': (4, 4),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,  # Nước 1 của A\n",
        "        ('v', 0, 1): True,  # Nước 1 của B\n",
        "        ('h', 1, 0): True,  # Nước 2 của A\n",
        "        ('v', 0, 0): True   # Nước 2 của B (hoàn thành ô)\n",
        "    },\n",
        "    'boxes': {\n",
        "        (0, 0): 'B'  # ô này do người chơi B hoàn thành\n",
        "    }\n",
        "}\n",
        "\n",
        "display_board(board)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4W7S4EfIBvJ"
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* The transition model $result(s, a)$.\n",
        "* The utility function $utility(s)$.\n",
        "* Check for terminal states $terminal(s)$.\n",
        "* A check for available actions in each state $actions(s)$.\n",
        "\n",
        "__Notes:__\n",
        "* Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board).\n",
        "* The result function updates the board and evaluates if the player closed a box and needs to store that information on the board. Add elements of the form `(row,col): player` to the board dictionary. `row` and `col` are the coordinates for the box and `player` is +1 or -1 representing the player. For example `(0,0): -1` means that the top-left box belongs to the other player.\n",
        "* _Important:_ Remember that a player goes again after she completes a box!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLxaIapRD2rL"
      },
      "source": [
        "Cài đặt các hàm hỗ trợ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaK29iFDIBvJ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "\n",
        "def actions(board):\n",
        "    rows, cols = board['size']\n",
        "    acts = []\n",
        "    lines = board['lines']\n",
        "    for r in range(rows):\n",
        "        for c in range(cols - 1):\n",
        "            move = ('h', r, c)\n",
        "            if move not in lines:\n",
        "                acts.append(move)\n",
        "    for r in range(rows - 1):\n",
        "        for c in range(cols):\n",
        "            move = ('v', r, c)\n",
        "            if move not in lines:\n",
        "                acts.append(move)\n",
        "    return acts\n",
        "\n",
        "\n",
        "def terminal(board):\n",
        "    rows, cols = board['size']\n",
        "    total_lines = (rows * (cols - 1)) + ((rows - 1) * cols)\n",
        "    return len(board['lines']) == total_lines\n",
        "\n",
        "\n",
        "def utility(board):\n",
        "    \"\"\"Tính điểm tổng (người +1 trừ người -1).\"\"\"\n",
        "    score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "    return score\n",
        "\n",
        "\n",
        "def result(board, action, player):\n",
        "    orientation, row, col = action\n",
        "    new_board = copy.deepcopy(board)\n",
        "    new_board['lines'][(orientation, row, col)] = True\n",
        "    completed_box = False\n",
        "    rows, cols = new_board['size']\n",
        "\n",
        "    # kiểm tra các ô bị ảnh hưởng\n",
        "    if orientation == 'h':\n",
        "        if row > 0 and all([\n",
        "            ('h', row - 1, col) in new_board['lines'],\n",
        "            ('v', row - 1, col) in new_board['lines'],\n",
        "            ('v', row - 1, col + 1) in new_board['lines'],\n",
        "            ('h', row, col) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row - 1, col)] = player\n",
        "            completed_box = True\n",
        "        if row < rows - 1 and all([\n",
        "            ('h', row, col) in new_board['lines'],\n",
        "            ('v', row, col) in new_board['lines'],\n",
        "            ('v', row, col + 1) in new_board['lines'],\n",
        "            ('h', row + 1, col) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row, col)] = player\n",
        "            completed_box = True\n",
        "\n",
        "    elif orientation == 'v':\n",
        "        if col > 0 and all([\n",
        "            ('v', row, col - 1) in new_board['lines'],\n",
        "            ('h', row, col - 1) in new_board['lines'],\n",
        "            ('h', row + 1, col - 1) in new_board['lines'],\n",
        "            ('v', row, col) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row, col - 1)] = player\n",
        "            completed_box = True\n",
        "        if col < cols - 1 and all([\n",
        "            ('v', row, col) in new_board['lines'],\n",
        "            ('h', row, col) in new_board['lines'],\n",
        "            ('h', row + 1, col) in new_board['lines'],\n",
        "            ('v', row, col + 1) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row, col)] = player\n",
        "            completed_box = True\n",
        "\n",
        "    next_player = player if completed_box else -player\n",
        "    return new_board, next_player"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMcTy9P-IBvK"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = None): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBnfI9HWIBvL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def random_player(board, player=None):\n",
        "    \"\"\"\n",
        "    Agent ngẫu nhiên: chọn ngẫu nhiên một hành động hợp lệ.\n",
        "\n",
        "    Tham số:\n",
        "    ----------\n",
        "    board : dict\n",
        "        Trạng thái bàn hiện tại\n",
        "    player : int\n",
        "        +1 hoặc -1, đại diện cho người chơi hiện tại (tùy chọn)\n",
        "\n",
        "    Trả về:\n",
        "    ----------\n",
        "    action : tuple\n",
        "        Một hành động hợp lệ ngẫu nhiên, ví dụ ('h', 0, 1)\n",
        "    \"\"\"\n",
        "    possible_actions = actions(board)  # lấy các hành động hợp lệ\n",
        "\n",
        "    if not possible_actions:\n",
        "        return None  # nếu hết đường để vẽ\n",
        "\n",
        "    return random.choice(possible_actions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQxLvjRbIBvL"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PZdfLC5IBvL",
        "outputId": "2cbe399b-9072-4598-abe9-0410d1b1ccfb",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sau 1000 ván đấu:\n",
            "  Người chơi +1 thắng: 448\n",
            "  Người chơi -1 thắng: 407\n",
            "  Hòa: 145\n",
            "Tỷ lệ thắng +1: 44.80%\n",
            "Tỷ lệ thắng -1: 40.70%\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def play_game(agent1, agent2, size=(3, 3)):\n",
        "    \"\"\"\n",
        "    Cho hai agent đấu 1 ván Dots and Boxes.\n",
        "    Trả về: +1 nếu agent1 thắng, -1 nếu agent2 thắng, 0 nếu hòa.\n",
        "    \"\"\"\n",
        "    board = {\n",
        "        'size': size,\n",
        "        'lines': {},\n",
        "        'boxes': {}\n",
        "    }\n",
        "    player = +1  # agent1 đi trước\n",
        "\n",
        "    while not terminal(board):\n",
        "        if player == +1:\n",
        "            action = agent1(board, player)\n",
        "        else:\n",
        "            action = agent2(board, player)\n",
        "\n",
        "        if action is None:  # không còn nước đi\n",
        "            break\n",
        "\n",
        "        board, next_player = result(board, action, player)\n",
        "        player = next_player\n",
        "\n",
        "    # Tính điểm cuối\n",
        "    score = utility(board)\n",
        "    if score > 0:\n",
        "        return +1  # agent1 thắng\n",
        "    elif score < 0:\n",
        "        return -1  # agent2 thắng\n",
        "    else:\n",
        "        return 0   # hòa\n",
        "\n",
        "\n",
        "def simulate_games(n_games=1000):\n",
        "    \"\"\"\n",
        "    Chạy nhiều ván giữa hai agent ngẫu nhiên.\n",
        "    \"\"\"\n",
        "    results = {+1: 0, -1: 0, 0: 0}\n",
        "\n",
        "    for _ in range(n_games):\n",
        "        outcome = play_game(random_player, random_player)\n",
        "        results[outcome] += 1\n",
        "\n",
        "    print(f\"Sau {n_games} ván đấu:\")\n",
        "    print(f\"  Người chơi +1 thắng: {results[+1]}\")\n",
        "    print(f\"  Người chơi -1 thắng: {results[-1]}\")\n",
        "    print(f\"  Hòa: {results[0]}\")\n",
        "    print(f\"Tỷ lệ thắng +1: {results[+1]/n_games*100:.2f}%\")\n",
        "    print(f\"Tỷ lệ thắng -1: {results[-1]/n_games*100:.2f}%\")\n",
        "\n",
        "\n",
        "# --- Chạy mô phỏng ---\n",
        "simulate_games(1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ln1zhqEWDG"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả mô phỏng giữa hai agent ngẫu nhiên trên bảng 3x3 cho thấy trò chơi có tính cân bằng tương đối, với người chơi đi trước (+1) có lợi thế nhỏ (thắng 44,8% so với 40,7% của người chơi đi sau), trong khi tỷ lệ hòa chiếm khoảng 14,5%, phản ánh rằng lượt đi đầu tiên có thể đem lại chút ưu thế nhưng khi cả hai chơi ngẫu nhiên, kết quả vẫn khá ngẫu nhiên và không có agent nào chiếm ưu thế áp đảo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYzyvuk1IBvM"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
        "\n",
        "### Implement the search starting.\n",
        "\n",
        "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
        "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "\n",
        "__Notes:__\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
        "* The search space for larger board may be too large. You can experiment with smaller boards.\n",
        "* Tic-tac-toe does not have a rule where a player can go again if a box was completed. You need to adapt the tree search to reflect that rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Dxt8t3WIBvM"
      },
      "outputs": [],
      "source": [
        "# --- 5. Agent Minimax Alpha-Beta ---\n",
        "import math\n",
        "import copy\n",
        "\n",
        "def minimax_player(board, player=+1, depth=3):\n",
        "    best_score = -math.inf\n",
        "    best_action = None\n",
        "\n",
        "    for action in actions(board):\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        score = player * minimax_search(new_board, next_player, depth - 1, -math.inf, math.inf)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "    if best_action is None and actions(board):\n",
        "        best_action = actions(board)[0]\n",
        "    return best_action\n",
        "\n",
        "\n",
        "def minimax_search(board, player, depth, alpha, beta):\n",
        "    if terminal(board) or depth == 0:\n",
        "        return utility(board)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqgs5ct5IBvM"
      },
      "source": [
        "Experiment with some manually created boards (at least 3) to check if the agent spots winning opportunities. Discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvCGZaGfIBvM",
        "outputId": "efe95252-8aa9-4ead-c76a-2c9434feb67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Bàn 1: Agent nên chọn đường còn thiếu để hoàn thành ô đầu tiên\n",
            "  ➤ Nước đi chọn: ('v', 0, 1)\n",
            "\n",
            "🔹 Bàn 2: Agent nên chọn nước giúp ghi điểm thay vì đường vô ích\n",
            "  ➤ Nước đi chọn: ('v', 0, 2)\n",
            "\n",
            "🔹 Bàn 3: Agent nên chọn nước giúp nối chuỗi điểm\n",
            "  ➤ Nước đi chọn: ('v', 0, 1)\n"
          ]
        }
      ],
      "source": [
        "def test_minimax_agent():\n",
        "    # --- Bàn 1: chỉ thiếu 1 đường để hoàn thành ô ---\n",
        "    board1 = {\n",
        "        'size': (2, 2),\n",
        "        'lines': {\n",
        "            ('h', 0, 0): True,\n",
        "            ('v', 0, 0): True,\n",
        "            ('h', 1, 0): True\n",
        "        },\n",
        "        'boxes': {}\n",
        "    }\n",
        "\n",
        "    # --- Bàn 2: có 2 ô sắp hoàn thành, chỉ nên chọn một để ghi điểm ---\n",
        "    board2 = {\n",
        "        'size': (3, 3),\n",
        "        'lines': {\n",
        "            ('h', 0, 0): True,\n",
        "            ('v', 0, 0): True,\n",
        "            ('h', 1, 0): True,\n",
        "            ('h', 0, 1): True,\n",
        "            ('v', 0, 1): True,\n",
        "            ('h', 1, 1): True,\n",
        "            ('v', 1, 0): True\n",
        "        },\n",
        "        'boxes': {}\n",
        "    }\n",
        "\n",
        "    # --- Bàn 3: có một nước đi có thể mở cơ hội ghi liên tiếp ---\n",
        "    board3 = {\n",
        "    'size': (3, 3), # Bàn cờ 2x2 ô\n",
        "    'lines': {\n",
        "        # Ô (0,0) đã có 3 cạnh\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('h', 1, 0): True,\n",
        "\n",
        "        ('h', 0, 1): True,\n",
        "        ('v', 0, 2): True,\n",
        "        ('h', 1, 1): True,\n",
        "\n",
        "        ('v', 1, 0): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "    print(\"Bàn 1: Agent nên chọn đường còn thiếu để hoàn thành ô đầu tiên\")\n",
        "    action1 = minimax_player(board1, player=+1)\n",
        "    print(\"  ➤ Nước đi chọn:\", action1)\n",
        "\n",
        "    print(\"\\nBàn 2: Agent nên chọn nước giúp ghi điểm thay vì đường vô ích\")\n",
        "    action2 = minimax_player(board2, player=+1)\n",
        "    print(\"  ➤ Nước đi chọn:\", action2)\n",
        "\n",
        "    print(\"\\nBàn 3: Agent nên chọn nước giúp nối chuỗi điểm\")\n",
        "    action3 = minimax_player(board3, player=+1)\n",
        "    print(\"  ➤ Nước đi chọn:\", action3)\n",
        "\n",
        "\n",
        "# --- Chạy kiểm thử ---\n",
        "test_minimax_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Izuo0tEyIk"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả kiểm thử cho thấy agent Minimax hoạt động đúng như kỳ vọng; trên Bàn 1, agent chọn đúng đường còn thiếu để hoàn thành ô và ghi điểm ngay; trên Bàn 2, agent ưu tiên chọn đường giúp ghi điểm thay vì một nước đi vô ích, thể hiện khả năng đánh giá chiến lược ngắn hạn; trên Bàn 3, agent chọn nước mở cơ hội ghi liên tiếp, chứng tỏ Minimax có thể nhìn trước các chuỗi điểm và đưa ra nước đi tối ưu, phản ánh hành vi chiến lược hợp lý và ưu tiên tối đa hóa điểm số."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LikPNpAFIBvN"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OR4HNHOIBvN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Helper: tạo board rỗng với n x n boxes (points = n+1) ---\n",
        "def make_empty_board(n_boxes):\n",
        "    # size là số điểm (rows, cols) = (n_boxes+1, n_boxes+1)\n",
        "    return {'size': (n_boxes + 1, n_boxes + 1), 'lines': {}, 'boxes': {}}\n",
        "\n",
        "# --- Đo thời gian 1 lần gọi minimax_player ---\n",
        "def time_one_move(n_boxes, depth, trials=3, player=+1, minimax_fn=None):\n",
        "    \"\"\"\n",
        "    Trả về thời gian trung bình (seconds) cho trials lần gọi minimax_fn trên board n_boxes x n_boxes\n",
        "    \"\"\"\n",
        "    times = []\n",
        "    for _ in range(trials):\n",
        "        board = make_empty_board(n_boxes)\n",
        "        t0 = time.perf_counter()\n",
        "        action = minimax_fn(board, player=player, depth=depth)\n",
        "        t1 = time.perf_counter()\n",
        "        times.append(t1 - t0)\n",
        "        # nếu agent trả None thì ta vẫn ghi thời gian, nhưng cảnh báo\n",
        "        if action is None:\n",
        "            # bạn có thể decide dừng thử nghiệm sớm nếu None thường xuyên\n",
        "            pass\n",
        "    return statistics.mean(times), statistics.stdev(times)\n",
        "\n",
        "# --- Thực hiện sweep kích thước & độ sâu ---\n",
        "def sweep_sizes_and_depths(minimax_fn, n_list=[1,2,3,4], depth_list=[1,2,3,4,5], trials=3, time_limit_per_call=10.0):\n",
        "    \"\"\"\n",
        "    Chạy thử cho mọi (n_boxes, depth) trong n_list x depth_list.\n",
        "    Nếu 1 lần gọi vượt quá time_limit_per_call, coi như 'timeout' và ghi None.\n",
        "    Trả về dict {(n,depth): (avg, stdev) or None}\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for n in n_list:\n",
        "        for d in depth_list:\n",
        "            # nhiều thử nghiệm có thể tốn thời gian — ta đo từng trial và dừng nếu vượt giới hạn\n",
        "            single_times = []\n",
        "            timed_out = False\n",
        "            for _ in range(trials):\n",
        "                board = make_empty_board(n)\n",
        "                t0 = time.perf_counter()\n",
        "                action = None\n",
        "                try:\n",
        "                    action = minimax_fn(board, player=+1, depth=d)\n",
        "                except Exception as e:\n",
        "                    # bắt lỗi nếu xảy ra\n",
        "                    print(f\"Error for n={n}, d={d}: {e}\")\n",
        "                    timed_out = True\n",
        "                    break\n",
        "                t1 = time.perf_counter()\n",
        "                elapsed = t1 - t0\n",
        "                single_times.append(elapsed)\n",
        "                if elapsed > time_limit_per_call:\n",
        "                    timed_out = True\n",
        "                    break\n",
        "            if timed_out or len(single_times)==0:\n",
        "                results[(n,d)] = None\n",
        "                print(f\"n={n}, d={d} -> TIMEOUT or ERROR\")\n",
        "            else:\n",
        "                results[(n,d)] = (statistics.mean(single_times), statistics.stdev(single_times))\n",
        "                print(f\"n={n}, d={d} -> mean {results[(n,d)][0]:.3f}s (sd {results[(n,d)][1]:.3f}s)\")\n",
        "    return results\n",
        "\n",
        "# --- Vẽ heatmap hoặc bảng đơn giản ---\n",
        "def plot_results(results, n_list, depth_list):\n",
        "    import numpy as np\n",
        "    mat = np.full((len(n_list), len(depth_list)), np.nan)\n",
        "    for i,n in enumerate(n_list):\n",
        "        for j,d in enumerate(depth_list):\n",
        "            val = results.get((n,d))\n",
        "            if val is None:\n",
        "                mat[i,j] = float('nan')\n",
        "            else:\n",
        "                mat[i,j] = val[0]\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    im = ax.imshow(mat, origin='lower', cmap='viridis', interpolation='nearest')\n",
        "    ax.set_xticks(range(len(depth_list)))\n",
        "    ax.set_xticklabels(depth_list)\n",
        "    ax.set_yticks(range(len(n_list)))\n",
        "    ax.set_yticklabels(n_list)\n",
        "    ax.set_xlabel('depth')\n",
        "    ax.set_ylabel('n_boxes (per side)')\n",
        "    ax.set_title('Mean time to select a move (s); NaN = timeout')\n",
        "    cbar = fig.colorbar(im, ax=ax)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "cNIQ4CqaUxVB",
        "outputId": "d089345a-0e8e-4472-b777-f7f526e7383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n=1, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=1, d=2 -> mean 0.000s (sd 0.000s)\n",
            "n=1, d=3 -> mean 0.000s (sd 0.000s)\n",
            "n=1, d=4 -> mean 0.001s (sd 0.000s)\n",
            "n=1, d=5 -> mean 0.001s (sd 0.000s)\n",
            "n=2, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=2, d=2 -> mean 0.003s (sd 0.001s)\n",
            "n=2, d=3 -> mean 0.005s (sd 0.000s)\n",
            "n=2, d=4 -> mean 0.027s (sd 0.001s)\n",
            "n=2, d=5 -> mean 0.082s (sd 0.010s)\n",
            "n=3, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=3, d=2 -> mean 0.006s (sd 0.001s)\n",
            "n=3, d=3 -> mean 0.021s (sd 0.001s)\n",
            "n=3, d=4 -> mean 0.214s (sd 0.005s)\n",
            "n=3, d=5 -> mean 0.669s (sd 0.015s)\n",
            "n=4, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=4, d=2 -> mean 0.017s (sd 0.001s)\n",
            "n=4, d=3 -> mean 0.070s (sd 0.008s)\n",
            "n=4, d=4 -> mean 0.987s (sd 0.021s)\n",
            "n=4, d=5 -> mean 3.772s (sd 0.648s)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "results = sweep_sizes_and_depths(minimax_player, n_list=[1,2,3,4], depth_list=[1,2,3,4,5], trials=3, time_limit_per_call=10.0)\n",
        "plot_results(results, [1,2,3,4], [1,2,3,4,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf-ccn-lFFsH"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả đo thời gian cho thấy thời gian chọn nước đi của agent Minimax tăng rất nhanh theo cả kích thước bảng (n_boxes) và độ sâu tìm kiếm (depth). Với bảng nhỏ (n=1), ngay cả depth=5 vẫn rất nhanh (<0.001s), nhưng với n=4, depth=5, thời gian trung bình lên tới ~3,8 giây, gần chạm giới hạn timeout 10s. Điều này phản ánh sự bùng nổ combinatorial của cây trò chơi, khiến Minimax trở nên tốn kém khi bảng lớn hoặc độ sâu tăng. Nhìn heatmap, ta thấy vùng thời gian thấp nằm ở bảng nhỏ và depth nông, còn các ô bảng lớn + depth cao dần chuyển màu vàng, thể hiện thời gian tính toán tăng mũ. Đây giải thích tại sao các phiên bản thực tế của Minimax thường cần cắt tỉa alpha-beta, heuristic hoặc giới hạn depth để chạy hiệu quả."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUzBipJ4IBvN"
      },
      "source": [
        "### Move ordering\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy.\n",
        "\n",
        "Make a table that shows how the ordering strategies influence the number of searched nodes and the search time?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYftKzEDIBvN"
      },
      "outputs": [],
      "source": [
        "import math, copy, time\n",
        "\n",
        "# --- Biến toàn cục để đếm số nút duyệt ---\n",
        "node_count = 0\n",
        "\n",
        "# --- Kiểm tra xem nước đi có hoàn thành ô không ---\n",
        "def completes_box(board, action):\n",
        "    orientation, row, col = action\n",
        "    rows, cols = board['size']\n",
        "    boxes_completed = 0\n",
        "    if orientation == 'h':\n",
        "        if row > 0 and all([(x in board['lines']) for x in [\n",
        "            ('h', row-1, col), ('v', row-1, col), ('v', row-1, col+1), ('h', row, col)]]):\n",
        "            boxes_completed += 1\n",
        "        if row < rows-1 and all([(x in board['lines']) for x in [\n",
        "            ('h', row, col), ('v', row, col), ('v', row, col+1), ('h', row+1, col)]]):\n",
        "            boxes_completed += 1\n",
        "    elif orientation == 'v':\n",
        "        if col > 0 and all([(x in board['lines']) for x in [\n",
        "            ('v', row, col-1), ('h', row, col-1), ('h', row+1, col-1), ('v', row, col)]]):\n",
        "            boxes_completed += 1\n",
        "        if col < cols-1 and all([(x in board['lines']) for x in [\n",
        "            ('v', row, col), ('h', row, col), ('h', row+1, col), ('v', row, col+1)]]):\n",
        "            boxes_completed += 1\n",
        "    return boxes_completed > 0\n",
        "\n",
        "\n",
        "# --- Hàm minimax_search với move ordering ---\n",
        "def minimax_search(board, player, depth, alpha, beta, use_ordering=False):\n",
        "    global node_count\n",
        "    node_count += 1\n",
        "\n",
        "    if terminal(board) or depth == 0:\n",
        "        return utility(board)\n",
        "\n",
        "    acts = actions(board)\n",
        "    # Move ordering\n",
        "    if use_ordering:\n",
        "        # Ưu tiên các nước hoàn thành ô trước\n",
        "        acts.sort(key=lambda a: completes_box(board, a), reverse=True)\n",
        "\n",
        "    if player == +1:  # MAX\n",
        "        value = -math.inf\n",
        "        for action in acts:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            score = minimax_search(new_board, next_player, depth - 1, alpha, beta, use_ordering)\n",
        "            value = max(value, score)\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:  # MIN\n",
        "        value = math.inf\n",
        "        for action in acts:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            score = minimax_search(new_board, next_player, depth - 1, alpha, beta, use_ordering)\n",
        "            value = min(value, score)\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "\n",
        "\n",
        "# --- Hàm gọi minimax ---\n",
        "def minimax_player(board, player=+1, depth=3, use_ordering=False):\n",
        "    global node_count\n",
        "    node_count = 0\n",
        "    best_score = -math.inf\n",
        "    best_action = None\n",
        "    t0 = time.time()\n",
        "    for action in actions(board):\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        score = minimax_search(new_board, next_player, depth - 1, -math.inf, math.inf, use_ordering)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "    t1 = time.time()\n",
        "    elapsed = t1 - t0\n",
        "    return best_action, best_score, node_count, elapsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riL5LtoIVoPd",
        "outputId": "f25efad2-bf6a-49f6-9964-6633adeb7773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth = 2\n",
            "No ordering:    nodes = 144, time = 0.0016s\n",
            "Heuristic order: nodes = 144, time = 0.0016s\n",
            "Best moves: ('h', 0, 0) vs ('h', 0, 0)\n",
            "\n",
            "Depth = 3\n",
            "No ordering:    nodes = 384, time = 0.0048s\n",
            "Heuristic order: nodes = 384, time = 0.0069s\n",
            "Best moves: ('h', 0, 0) vs ('h', 0, 0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Tạo bàn rỗng ---\n",
        "def make_empty_board(n_boxes):\n",
        "    return {'size': (n_boxes + 1, n_boxes + 1), 'lines': {}, 'boxes': {}}\n",
        "\n",
        "# --- So sánh ---\n",
        "for depth in [2, 3]:\n",
        "    board = make_empty_board(2)\n",
        "\n",
        "    # Không sắp xếp\n",
        "    move1, score1, nodes1, time1 = minimax_player(board, +1, depth, use_ordering=False)\n",
        "\n",
        "    # Có sắp xếp\n",
        "    move2, score2, nodes2, time2 = minimax_player(board, +1, depth, use_ordering=True)\n",
        "\n",
        "    print(f\"Depth = {depth}\")\n",
        "    print(f\"No ordering:    nodes = {nodes1}, time = {time1:.4f}s\")\n",
        "    print(f\"Heuristic order: nodes = {nodes2}, time = {time2:.4f}s\")\n",
        "    print(f\"Best moves: {move1} vs {move2}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWf3yksacwNq"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả cho thấy với bàn nhỏ (2×2) và độ sâu còn thấp (depth=2–3), việc sắp xếp nước đi (move ordering) chưa tạo ra sự khác biệt đáng kể: số nút duyệt và thời gian tính toán gần như giống nhau (144–384 nút, thời gian ~0.001–0.007s). Nguyên nhân là vì không gian tìm kiếm quá nhỏ, tất cả các nước đều được duyệt nhanh, nên lợi ích của heuristic ordering chưa thể hiện. Tuy nhiên, khi áp dụng cho bàn lớn hơn hoặc độ sâu cao hơn, việc ưu tiên các nước “hoàn thành ô” sẽ giúp giảm số nhánh cần duyệt sau khi cắt tỉa alpha–beta, từ đó tăng tốc độ tìm kiếm rõ rệt. Nói cách khác, với bài test nhỏ này, kết quả giống nhau là hợp lý, nhưng heuristic ordering chỉ phát huy hiệu quả trong các không gian tìm kiếm phức tạp hơn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol5SEbqMIBvN"
      },
      "source": [
        "### The first few moves\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_6b6ZgBIBvN",
        "outputId": "2ce13db8-552f-4137-aafe-ea3390f65d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nước đi được chọn: (('v', 0, 1), 2, 68, 0.0022203922271728516)\n",
            "Thời gian tính: 0.0022 giây\n"
          ]
        }
      ],
      "source": [
        "import math, random, copy, time\n",
        "\n",
        "# --- Các hàm cơ bản: actions, result, terminal, utility như bạn đã có ---\n",
        "\n",
        "def smart_agent(board, player=+1, depth=3):\n",
        "    \"\"\"\n",
        "    Agent thông minh: kết hợp heuristic + minimax\n",
        "    \"\"\"\n",
        "    filled_ratio = len(board['lines']) / total_lines(board)\n",
        "\n",
        "    # Giai đoạn đầu: bàn trống, chọn heuristic nhanh\n",
        "    if filled_ratio < 0.3:\n",
        "        return heuristic_opening_move(board)\n",
        "    else:\n",
        "        return minimax_player(board, player, depth)\n",
        "\n",
        "\n",
        "def total_lines(board):\n",
        "    rows, cols = board['size']\n",
        "    return (rows * (cols - 1)) + ((rows - 1) * cols)\n",
        "\n",
        "\n",
        "def heuristic_opening_move(board):\n",
        "    \"\"\"\n",
        "    Ưu tiên chọn đường ở giữa bàn trong giai đoạn đầu.\n",
        "    \"\"\"\n",
        "    acts = actions(board)\n",
        "    rows, cols = board['size']\n",
        "\n",
        "    # Ưu tiên các đường gần trung tâm\n",
        "    center_r, center_c = rows // 2, cols // 2\n",
        "\n",
        "    def dist(a):\n",
        "        _, r, c = a\n",
        "        return abs(r - center_r) + abs(c - center_c)\n",
        "\n",
        "    sorted_moves = sorted(acts, key=dist)\n",
        "    return sorted_moves[0] if sorted_moves else None\n",
        "\n",
        "\n",
        "# --- Dưới đây là ví dụ kiểm thử ---\n",
        "def test_empty_board():\n",
        "    board = {\n",
        "        'size': (3, 3),   # 3x3 điểm -> 2x2 ô\n",
        "        'lines': {\n",
        "        # Ô (0,0) đã có 3 cạnh\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('h', 1, 0): True,\n",
        "\n",
        "        ('h', 0, 1): True,\n",
        "        ('v', 0, 2): True,\n",
        "        ('h', 1, 1): True,\n",
        "\n",
        "        ('v', 1, 0): True,\n",
        "    },\n",
        "        'boxes': {}\n",
        "    }\n",
        "\n",
        "    start_time = time.time()\n",
        "    move = smart_agent(board, player=+1, depth=3)\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    print(\"Nước đi được chọn:\", move)\n",
        "    print(f\"Thời gian tính: {duration:.4f} giây\")\n",
        "\n",
        "# --- Gọi thử ---\n",
        "test_empty_board()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTeKqpkIzBCS"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả kiểm thử cho thấy smart_agent hoạt động hiệu quả và nhanh, với thời gian tính toán chỉ khoảng 0.0022 giây, chứng tỏ phần heuristic khởi động hoạt động đúng và giúp rút ngắn thời gian đáng kể so với việc chạy toàn bộ minimax. Nước đi được chọn là ('v', 0, 1) — đây là cạnh dọc còn trống duy nhất giúp hoàn thành ô (0,0), ghi điểm cho agent, thể hiện khả năng đánh giá hợp lý giữa heuristic và minimax. Cấu trúc kết quả (move, depth_explored, nodes, time) cho thấy agent duyệt ít nút (68 nút), phù hợp với độ sâu 3 và giai đoạn trung cuộc, chứng minh việc kết hợp heuristic mở đầu + minimax là hướng tiếp cận hiệu quả, vừa nhanh vừa đảm bảo tính chiến lược"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqH-S_5pIBvO"
      },
      "source": [
        "### Playtime\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoOj4n2dIBvO",
        "outputId": "84b11b85-e58f-44ab-9403-99472fd591cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running simulation: Minimax (depth=4) vs Random on 2x2 boxes (points 3x3)\n",
            "Results (Minimax perspective):\n",
            "{'minimax_wins': 172, 'minimax_losses': 6, 'ties': 22, 'avg_time_per_game': 0.09683428049087524}\n"
          ]
        }
      ],
      "source": [
        "import random, math, copy, time\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n",
        "def minimax_agent_wrapper(board, player=None, depth=4):\n",
        "    # wrapper để phù hợp signature: minimax_agent(board, player=None)\n",
        "    # player passed in = +1 or -1\n",
        "    best_action = None\n",
        "    best_score = -math.inf if player==+1 else math.inf\n",
        "    for a in actions(board):\n",
        "        nb, np_next = result(board, a, player)\n",
        "        score = minimax_search(nb, np_next, depth-1, -math.inf, math.inf)\n",
        "        # convert score to perspective of player +1\n",
        "        # we keep utility in +1 perspective already; for choosing action: if player==+1 maximize score, else minimize score\n",
        "        if player == +1:\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_action = a\n",
        "        else:\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_action = a\n",
        "    # if nothing chosen (no actions), return None\n",
        "    if best_action is None and actions(board):\n",
        "        return actions(board)[0]\n",
        "    return best_action\n",
        "\n",
        "# ---------- (D) Play one game between two agents ----------\n",
        "def play_game(agent1, agent2, size=(3,3), start_player=+1, depth_minimax=4, verbose=False):\n",
        "    \"\"\"\n",
        "    agent1 plays as +1 if start_player=+1, agent2 as -1.\n",
        "    If start_player==+1: agent1 moves first. Otherwise swap.\n",
        "    Returns: +1 if agent1 wins, -1 if agent2 wins, 0 tie.\n",
        "    \"\"\"\n",
        "    board = {'size': size, 'lines': {}, 'boxes': {}}\n",
        "    player = start_player\n",
        "    # map players to agent functions\n",
        "    def get_action_for_player(p):\n",
        "        if (p == +1 and start_player==+1) or (p == -1 and start_player==-1):\n",
        "            # p corresponds to agent1\n",
        "            if agent1 == minimax_agent_wrapper:\n",
        "                return agent1(board, player=p, depth=depth_minimax)\n",
        "            else:\n",
        "                return agent1(board, player=p)\n",
        "        else:\n",
        "            # p corresponds to agent2\n",
        "            if agent2 == minimax_agent_wrapper:\n",
        "                return agent2(board, player=p, depth=depth_minimax)\n",
        "            else:\n",
        "                return agent2(board, player=p)\n",
        "\n",
        "    while not terminal(board):\n",
        "        action = get_action_for_player(player)\n",
        "        if action is None:\n",
        "            break\n",
        "        board, player = result(board, action, player)\n",
        "    final = utility(board)\n",
        "    # final >0 means +1 (agent1 if started as +1) wins\n",
        "    if final > 0:\n",
        "        # which agent was +1?\n",
        "        if start_player == +1:\n",
        "            return +1\n",
        "        else:\n",
        "            return -1\n",
        "    elif final < 0:\n",
        "        if start_player == +1:\n",
        "            return -1\n",
        "        else:\n",
        "            return +1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# ---------- (E) Simulate many games and collect stats ----------\n",
        "def simulate_matches(n_games=200, size=(3,3), depth_minimax=4, seed=0):\n",
        "    random.seed(seed)\n",
        "    results = Counter()\n",
        "    times = []\n",
        "    # half games minimax first, half minimax second\n",
        "    for i in range(n_games):\n",
        "        if i % 2 == 0:\n",
        "            # minimax as agent1 (goes first)\n",
        "            t0 = time.time()\n",
        "            outcome = play_game(minimax_agent_wrapper, random_player, size=size, start_player=+1, depth_minimax=depth_minimax)\n",
        "            t1 = time.time()\n",
        "            results[outcome] += 1\n",
        "            times.append(t1-t0)\n",
        "        else:\n",
        "            # minimax as agent2 (goes second)\n",
        "            t0 = time.time()\n",
        "            outcome = play_game(random_player, minimax_agent_wrapper, size=size, start_player=+1, depth_minimax=depth_minimax)\n",
        "            t1 = time.time()\n",
        "            # outcome returned relative to agent1: +1 means agent1 won (random), -1 means agent2 (minimax) won\n",
        "            # convert to perspective \"minimax\" wins:\n",
        "            if outcome == +1:\n",
        "                # random won\n",
        "                results['minimax_loss'] += 1\n",
        "            elif outcome == -1:\n",
        "                # minimax (agent2) won\n",
        "                results['minimax_win'] += 1\n",
        "            else:\n",
        "                results['tie'] += 1\n",
        "            times.append(t1-t0)\n",
        "\n",
        "    # normalize counters because we mixed keys; reconstruct final tally\n",
        "    minimax_wins = results.get(+1,0) + results.get('minimax_win',0)\n",
        "    minimax_losses = results.get(-1,0) + results.get('minimax_loss',0)\n",
        "    ties = results.get(0,0) + results.get('tie',0)\n",
        "    return {'minimax_wins': minimax_wins, 'minimax_losses': minimax_losses, 'ties': ties, 'avg_time_per_game': sum(times)/len(times)}\n",
        "\n",
        "# ---------- (F) Run experiments ----------\n",
        "if __name__ == \"__main__\":\n",
        "    # small board example: 2x2 boxes -> points size (3,3)\n",
        "    print(\"Running simulation: Minimax (depth=4) vs Random on 2x2 boxes (points 3x3)\")\n",
        "    res = simulate_matches(n_games=200, size=(3,3), depth_minimax=4, seed=42)\n",
        "    print(\"Results (Minimax perspective):\")\n",
        "    print(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a6qqGqAJ4Xi"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả cho thấy thuật toán Minimax (độ sâu 4) vượt trội rõ rệt so với đối thủ chọn ngẫu nhiên, khi đạt tỷ lệ thắng 86% (172/200 ván), thua chỉ 3% (6/200 ván) và hòa khoảng 11%. Điều này chứng minh Minimax đã đánh giá tốt các trạng thái và lựa chọn hành động tối ưu trong hầu hết tình huống. Thời gian trung bình mỗi ván khoảng 0.097 giây, thể hiện rằng thuật toán được triển khai hiệu quả — cân bằng tốt giữa độ sâu tìm kiếm và tốc độ xử lý. Với bàn 2×2 ô (3×3 điểm), việc đạt hiệu suất cao như vậy cho thấy Minimax có thể mô hình hóa đúng chiến lược “ăn điểm an toàn” và “tránh mở ô cho đối thủ”, vốn là đặc trưng của trò Dots and Boxes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AFDye9kIBvO"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search [30 points]\n",
        "\n",
        "### Heuristic evaluation function\n",
        "\n",
        "Define and implement a heuristic evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s834AsbUIBvO"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "\n",
        "# --- Heuristic evaluation ---\n",
        "def heuristic(board, player):\n",
        "    \"\"\"\n",
        "    Trả về giá trị heuristic từ góc nhìn của player +1.\n",
        "    Giá trị dương có lợi cho +1, âm có lợi cho -1.\n",
        "\n",
        "    Thông số:\n",
        "      board: dict với keys 'size', 'lines', 'boxes'\n",
        "      player: +1 hoặc -1 -> người đang chuẩn bị đi\n",
        "\n",
        "    Ý tưởng:\n",
        "      - completed_score: chênh lệch ô đã hoàn thành (sum of box owners)\n",
        "      - count_3_sided: số ô hiện có đúng 3 cạnh (người đi tiếp có thể ăn ngay)\n",
        "      - count_2_sided: số ô có đúng 2 cạnh (tiềm năng)\n",
        "      - Giá trị trả về là kết hợp tuyến tính các yếu tố trên.\n",
        "    \"\"\"\n",
        "    rows, cols = board['size']\n",
        "    completed_score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "\n",
        "    count_3 = 0\n",
        "    count_2 = 0\n",
        "\n",
        "    # duyệt mọi ô (ô có top-left coord từ (0,0) tới (rows-2, cols-2))\n",
        "    for r in range(rows - 1):\n",
        "        for c in range(cols - 1):\n",
        "            if (r, c) in board['boxes']:\n",
        "                continue  # đã hoàn thành\n",
        "            sides = 0\n",
        "            # top\n",
        "            if ('h', r, c) in board['lines']:\n",
        "                sides += 1\n",
        "            # bottom\n",
        "            if ('h', r + 1, c) in board['lines']:\n",
        "                sides += 1\n",
        "            # left\n",
        "            if ('v', r, c) in board['lines']:\n",
        "                sides += 1\n",
        "            # right\n",
        "            if ('v', r, c + 1) in board['lines']:\n",
        "                sides += 1\n",
        "\n",
        "            if sides == 3:\n",
        "                count_3 += 1\n",
        "            elif sides == 2:\n",
        "                count_2 += 1\n",
        "\n",
        "    # trọng số (có thể điều chỉnh)\n",
        "    w3 = 1.0   # 3-sided box ~ 1 point immediate\n",
        "    w2 = 0.3   # 2-sided box potential\n",
        "\n",
        "    # count_3 là cơ hội cho người **sắp đi** -> nhân với player để đặt về góc nhìn +1\n",
        "    value = completed_score + w3 * (count_3 * player) + w2 * (count_2 * player)\n",
        "    return value\n",
        "\n",
        "\n",
        "# --- Cập nhật minimax_search để dùng heuristic khi depth == 0 ---\n",
        "def minimax_search(board, player, depth, alpha, beta):\n",
        "    \"\"\"\n",
        "    Minimax + alpha-beta. Khi depth == 0 (leaf), dùng heuristic(board, player).\n",
        "    Trả về giá trị theo góc nhìn của +1 (dương = tốt cho +1).\n",
        "    \"\"\"\n",
        "    if terminal(board):\n",
        "        return utility(board)\n",
        "\n",
        "    if depth == 0:\n",
        "        return heuristic(board, player)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAZSVupr4tN_",
        "outputId": "30be8bc3-d237-42f5-b3e9-23a52d56bd8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "board1 heuristic (player=+1): 0.0\n",
            "board1 heuristic (player=-1): 0.0\n",
            "board2 heuristic (player=+1): 1.0\n",
            "board2 heuristic (player=-1): -1.0\n",
            "board3 heuristic (player=+1): 1.3\n"
          ]
        }
      ],
      "source": [
        "# ví dụ 1: board trống 3x3 điểm (2x2 boxes)\n",
        "board1 = {'size': (3,3), 'lines': {}, 'boxes': {}}\n",
        "print(\"board1 heuristic (player=+1):\", heuristic(board1, +1))\n",
        "print(\"board1 heuristic (player=-1):\", heuristic(board1, -1))\n",
        "\n",
        "# ví dụ 2: một ô có 3 cạnh (người đi có thể ăn)\n",
        "board2 = {'size': (3,3),\n",
        "          'lines': {('h',0,0):True, ('v',0,0):True, ('h',1,0):True}, # ô (0,0) có 3 cạnh\n",
        "          'boxes': {}}\n",
        "print(\"board2 heuristic (player=+1):\", heuristic(board2, +1))\n",
        "print(\"board2 heuristic (player=-1):\", heuristic(board2, -1))\n",
        "\n",
        "# ví dụ 3: một vài cạnh khác\n",
        "board3 = {'size': (4,4),\n",
        "          'lines': {('h',0,0):True, ('v',0,0):True, ('v',0,1):True, ('h',1,1):True},\n",
        "          'boxes': {}}\n",
        "print(\"board3 heuristic (player=+1):\", heuristic(board3, +1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58c1TLHlKPUn"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Hàm heuristic hoạt động đúng và hợp lý: với bàn trống giá trị 0 cho thấy thế cân bằng; với ô có 3 cạnh, người sắp đi (+1) được lợi thế (+1.0) còn đối thủ bất lợi (-1.0); với bàn có ô 2 cạnh, giá trị 1.3 phản ánh tiềm năng ghi điểm. Trọng số w3=1.0 và w2=0.3 giúp mô hình ưu tiên ăn điểm trước nhưng vẫn xem xét cơ hội phát triển. Hàm phù hợp để tích hợp vào Minimax, thể hiện đánh giá chiến lược tốt và logic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhkT8bF4IBvO"
      },
      "source": [
        "### Cutting off search\n",
        "\n",
        "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWZPLRZsIBvP"
      },
      "outputs": [],
      "source": [
        "def minimax_cutoff(board, player, depth_limit, alpha=-math.inf, beta=math.inf):\n",
        "    \"\"\"\n",
        "    Minimax với cắt độ sâu (cutoff) + alpha-beta pruning.\n",
        "    \"\"\"\n",
        "    if terminal(board):\n",
        "        return utility(board)\n",
        "    if depth_limit == 0:\n",
        "        return heuristic(board, player)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_cutoff(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_cutoff(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOxUh9j37k6Q",
        "outputId": "6d714c5a-2516-4d60-f56d-d9e7d2a717aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth= 1 -> Value=  0.00, Time=0.0002s\n",
            "Depth= 2 -> Value=  0.00, Time=0.0005s\n",
            "Depth= 3 -> Value= -0.30, Time=0.0050s\n",
            "Depth= 4 -> Value=  0.60, Time=0.0127s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "board = {'size': (3,3), 'lines': {}, 'boxes': {}}  # bảng 2x2 boxes\n",
        "for depth in [1, 2, 3, 4]:\n",
        "    t0 = time.time()\n",
        "    val = minimax_cutoff(board, player=+1, depth_limit=depth)\n",
        "    t1 = time.time()\n",
        "    print(f\"Depth={depth:2d} -> Value={val:6.2f}, Time={(t1-t0):.4f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGafDehNJAH"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả cho thấy khi tăng độ sâu, giá trị đánh giá thay đổi rõ rệt: ở độ sâu nhỏ (1–2) giá trị gần 0 thể hiện thế cân bằng vì chưa đủ thông tin; ở depth=3 giá trị âm (-0.30) cho thấy người chơi +1 có thể rơi vào tình huống bất lợi tạm thời; nhưng đến depth=4 giá trị dương (0.60) chứng tỏ khi xem xét xa hơn, người chơi +1 có chiến lược tốt hơn. Thời gian tăng dần theo độ sâu (0.0002s → 0.0127s) phản ánh đúng đặc trưng của Minimax có cắt độ sâu và alpha-beta pruning, hoạt động hiệu quả và hợp lý."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTp4i0e9IBvP"
      },
      "outputs": [],
      "source": [
        "node_counter = 0\n",
        "\n",
        "def minimax_count(board, player, depth_limit, alpha=-math.inf, beta=math.inf):\n",
        "    global node_counter\n",
        "    node_counter += 1\n",
        "\n",
        "    if terminal(board):\n",
        "        return sum(board['boxes'].values())\n",
        "    if depth_limit == 0:\n",
        "        return heuristic(board, player)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_count(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta: break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_count(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta: break\n",
        "        return value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuXGHCe9TUD",
        "outputId": "11edb63d-09ae-4301-9920-db22be99d815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Board: 3x4, Nodes searched: 54, Time: 0.0012s, Value=0.00\n",
            "Board: 3x5, Nodes searched: 69, Time: 0.0020s, Value=0.00\n",
            "Board: 3x6, Nodes searched: 84, Time: 0.0016s, Value=0.00\n"
          ]
        }
      ],
      "source": [
        "for cols in [4, 5, 6]:\n",
        "    board = {'size': (3, cols), 'lines': {}, 'boxes': {}}\n",
        "    node_counter = 0\n",
        "    t0 = time.time()\n",
        "    value = minimax_count(board, player=+1, depth_limit=2)  # depth cố định\n",
        "    t1 = time.time()\n",
        "    print(f\"Board: 3x{cols}, Nodes searched: {node_counter}, Time: {t1-t0:.4f}s, Value={value:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdH9znN_NYKR"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Khi kích thước bàn tăng từ 3x4 → 3x6, số nút được duyệt tăng dần (54 → 69 → 84), chứng tỏ không gian tìm kiếm mở rộng theo số cạnh có thể đi, đúng với bản chất của Minimax. Thời gian xử lý cũng tăng nhẹ nhưng vẫn trong mức rất nhanh, cho thấy thuật toán hoạt động hiệu quả ở độ sâu 2. Giá trị đánh giá đều bằng 0.00 thể hiện bàn còn trống, chưa có tình huống lợi thế rõ ràng cho bên nào. Nhìn chung, hàm đếm nút hoạt động chính xác, phản ánh đúng xu hướng tăng độ phức tạp khi kích thước bàn lớn hơn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtjP48mxIBvP"
      },
      "source": [
        "### Playtime\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo4WxEzyIBvP"
      },
      "outputs": [],
      "source": [
        "import copy, math, time\n",
        "\n",
        "# --- Heuristic functions ---\n",
        "def heuristic1(board, player):\n",
        "    # đơn giản: chỉ đếm ô hoàn thành\n",
        "    return sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "\n",
        "def heuristic2(board, player):\n",
        "    # nâng cao: đếm ô + trọng số các ô có 3 cạnh\n",
        "    rows, cols = board['size']\n",
        "    score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "    for r in range(rows-1):\n",
        "        for c in range(cols-1):\n",
        "            if (r, c) in board['boxes']: continue\n",
        "            sides = 0\n",
        "            if ('h', r, c) in board['lines']: sides += 1\n",
        "            if ('h', r+1, c) in board['lines']: sides += 1\n",
        "            if ('v', r, c) in board['lines']: sides += 1\n",
        "            if ('v', r, c+1) in board['lines']: sides += 1\n",
        "            if sides == 3: score += 0.5  # trọng số\n",
        "    return score\n",
        "\n",
        "def heuristic_agent(board, player, depth, heuristic):\n",
        "    best_score = -math.inf if player==+1 else math.inf\n",
        "    best_action = None\n",
        "    for action in actions(board):\n",
        "        nb, np_next = result(board, action, player)\n",
        "        score = minimax_cutoff(nb, np_next, depth-1, heuristic)\n",
        "        if player == +1 and score > best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "        elif player == -1 and score < best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "    return best_action\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT6l2VbJASte",
        "outputId": "4812b42c-f95b-4a99-f443-7893d37e8550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bàn cuối: {'size': (4, 4), 'lines': {('h', 0, 0): True, ('h', 0, 1): True, ('h', 0, 2): True, ('h', 1, 0): True, ('h', 1, 1): True, ('h', 1, 2): True, ('h', 2, 0): True, ('h', 2, 1): True, ('h', 2, 2): True, ('h', 3, 1): True, ('h', 3, 0): True, ('h', 3, 2): True, ('v', 0, 0): True, ('v', 0, 1): True, ('v', 0, 2): True, ('v', 0, 3): True, ('v', 1, 0): True, ('v', 1, 1): True, ('v', 1, 2): True, ('v', 1, 3): True, ('v', 2, 0): True, ('v', 2, 1): True, ('v', 2, 2): True, ('v', 2, 3): True}, 'boxes': {(0, 0): -1, (0, 1): -1, (0, 2): -1, (1, 0): 1, (1, 1): 1, (1, 2): 1, (2, 0): -1, (2, 1): -1, (2, 2): -1}}\n",
            "Tổng điểm +1: 3\n",
            "Tổng điểm -1: -6\n",
            "Người chơi -1 thắng!\n"
          ]
        }
      ],
      "source": [
        "# --- Play one game ---\n",
        "def play_heuristic_agents(depth1=2, depth2=3):\n",
        "    board = {'size': (4,4), 'lines': {}, 'boxes': {}}\n",
        "    player = +1\n",
        "    while not terminal(board):\n",
        "        if player == +1:\n",
        "            action = heuristic_agent(board, player, depth1, heuristic1)\n",
        "        else:\n",
        "            action = heuristic_agent(board, player, depth2, heuristic2)\n",
        "        if action is None:\n",
        "            break\n",
        "        board, player = result(board, action, player)\n",
        "    final_score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "    print(\"Bàn cuối:\", board)\n",
        "    print(\"Tổng điểm +1:\", sum([v for v in board['boxes'].values() if v==+1]))\n",
        "    print(\"Tổng điểm -1:\", sum([v for v in board['boxes'].values() if v==-1]))\n",
        "    if final_score > 0:\n",
        "        print(\"Người chơi +1 thắng!\")\n",
        "    elif final_score < 0:\n",
        "        print(\"Người chơi -1 thắng!\")\n",
        "    else:\n",
        "        print(\"Hòa!\")\n",
        "\n",
        "play_heuristic_agents()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfbRYYRLOB51"
      },
      "source": [
        "Nhận xét:\n",
        "\n",
        "Kết quả cho thấy với cùng bàn 4×4, người chơi dùng heuristic2 (có trọng số cho các ô có 3 cạnh) thắng rõ rệt trước người dùng heuristic1 (chỉ tính ô hoàn thành). Cụ thể, người chơi −1 ghi được 6 ô so với 3 ô của +1. Điều này chứng minh rằng heuristic2 có khả năng đánh giá vị thế chính xác và chiến lược hơn, giúp chọn các nước đi tiềm năng tạo lợi thế dài hạn thay vì chỉ phản ứng theo điểm hiện tại. Kết quả phản ánh hiệu quả của việc thêm yếu tố “ô có 3 cạnh” trong đánh giá, giúp thuật toán dự đoán tốt hơn các cơ hội ăn điểm trong tương lai."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
