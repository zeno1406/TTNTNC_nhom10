{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HhWD12pIBvA"
      },
      "source": [
        "# Adversarial Search: Playing Dots and Boxes\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undegraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play the game Dots and Boxes:\n",
        "\n",
        "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
        "\n",
        "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgHaUbhoIBvC"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem associated with this game:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model\n",
        "* Test for the terminal state\n",
        "* Utility for terminal states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7kBSiFIBvD"
      },
      "outputs": [],
      "source": [
        "def initial_state(size=2):\n",
        "  # tr·∫£ v·ªÅ dictionary\n",
        "    return {\n",
        "        \"size\": size,\n",
        "        #cac ƒë∆∞·ªùng k·∫Ω ƒë√£ dc v·∫Ω\n",
        "        \"lines\": set(),\n",
        "        # l∆∞u ƒëi·ªÉm 2 ng chs ban ƒë·∫ßu\n",
        "        \"scores\": {1: 0, 2: 0},\n",
        "        \"player\": 1\n",
        "    }\n",
        "\n",
        "def actions(state):\n",
        "    n = state[\"size\"]\n",
        "    all_edges = set()\n",
        "    # T·∫°o t·∫•t c·∫£ c√°c c·∫°nh h·ª£p l·ªá (ngang v√† d·ªçc)\n",
        "    for x in range(n+1):\n",
        "        for y in range(n+1):\n",
        "            if x < n:\n",
        "                all_edges.add(((x, y), (x+1, y)))  # d·ªçc\n",
        "            if y < n:\n",
        "                all_edges.add(((x, y), (x, y+1)))  # ngang\n",
        "    return list(all_edges - state[\"lines\"])\n",
        "\n",
        "def check_completed_boxes(state, action):\n",
        "    # H√†m ki·ªÉm tra s·ªë √¥ vu√¥ng ho√†n th√†nh\n",
        "    # (c√≥ th·ªÉ t·∫°m gi·∫£ ƒë·ªãnh tr·∫£ 0 ƒë·ªÉ ƒë·ªãnh nghƒ©a m√¥ h√¨nh c∆° b·∫£n)\n",
        "    return 0\n",
        "\n",
        "def transition_model(state, action):\n",
        "  #chuy·ªÉn ƒë·ªìi tr·∫°ng th√°i sau m·ªói h√†nh ƒë·ªông\n",
        "    new_state = {\n",
        "        \"size\": state[\"size\"],\n",
        "        \"lines\": state[\"lines\"].copy(),\n",
        "        \"scores\": state[\"scores\"].copy(),\n",
        "        \"player\": state[\"player\"]\n",
        "    }\n",
        "    new_state[\"lines\"].add(action)\n",
        "    completed_boxes = check_completed_boxes(new_state, action)\n",
        "    #tr·∫°ng th√°i ho√†n th√†nh 1 √¥\n",
        "    if completed_boxes > 0:\n",
        "        new_state[\"scores\"][state[\"player\"]] += completed_boxes\n",
        "    else:\n",
        "      #L∆∞·ª£t ch∆°i ƒë∆∞·ª£c chuy·ªÉn cho ƒë·ªëi th·ªß\n",
        "        new_state[\"player\"] = 1 if state[\"player\"] == 2 else 2\n",
        "    return new_state\n",
        "\n",
        "#N√≥ ki·ªÉm tra xem tr√≤ ch∆°i ƒë√£ k·∫øt th√∫c hay ch∆∞a\n",
        "def is_terminal(state):\n",
        "    total_edges = state[\"size\"] * (state[\"size\"] + 1) * 2\n",
        "    return len(state[\"lines\"]) == total_edges\n",
        "# tr·∫£ v·ªÅ hi·ªáu s·ªë c·ªßa 2 ng chs\n",
        "def utility(state, player):\n",
        "    return state[\"scores\"][player] - state[\"scores\"][3 - player]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UU7zKGLIBvE"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jBcUavIBvF",
        "outputId": "7643fa72-3a1c-4eaf-e11f-a94127a6deb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n=1: E=4, upper bound states (with player) = 32\n",
            "n=2: E=12, upper bound states (with player) = 8,192\n",
            "n=3: E=24, upper bound states (with player) = 33,554,432\n",
            "n=4: E=40, upper bound states (with player) = 2,199,023,255,552\n",
            "n=5: E=60, upper bound states (with player) = 2,305,843,009,213,693,952\n",
            "n=6: E=84, upper bound states (with player) = 38,685,626,227,668,133,590,597,632\n"
          ]
        }
      ],
      "source": [
        "def edges_count(n):\n",
        "    # n = s·ªë √¥ theo h√†ng/ c·ªôt\n",
        "    return 2 * n * (n + 1)\n",
        "#T√≠nh ∆∞·ªõc l∆∞·ª£ng tr√™n (upper bound) cho s·ªë l∆∞·ª£ng tr·∫°ng th√°i c√≥ th·ªÉ c√≥ c·ªßa tr√≤ ch∆°i\n",
        "def state_space_upper_bound(n, include_player=True):\n",
        "    E = edges_count(n)\n",
        "    if include_player:\n",
        "        return 2 ** (E + 1)\n",
        "    else:\n",
        "        return 2 ** E\n",
        "\n",
        "for n in [1,2,3,4,5,6]:\n",
        "    E = edges_count(n)\n",
        "    ub = state_space_upper_bound(n)\n",
        "    print(f\"n={n}: E={E}, upper bound states (with player) = {ub:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQEhq-5vB5v3"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "S·ªë ƒë∆∞·ªùng tƒÉng theo c√¥ng th·ª©c b·∫≠c hai E = 2¬∑n¬∑(n+1), s·ªë tr·∫°ng th√°i tƒÉng theo h√†m m≈© 2^(E+1), v·ªõi n nh·ªè (1-2) c√≥ th·ªÉ gi·∫£i to√†n b·ªô, n=3 ƒë√£ ~33 tri·ªáu tr·∫°ng th√°i, n‚â•4 l√™n ƒë·∫øn h√†ng t·ª∑ t·ªâ, cho th·∫•y vi·ªác duy·ªát to√†n b·ªô kh√¥ng gian tr·∫°ng th√°i l√† kh√¥ng kh·∫£ thi, c·∫ßn c·∫Øt t·ªâa, heuristic ho·∫∑c ph∆∞∆°ng ph√°p x·∫•p x·ªâ; vi·ªác t√≠nh th√™m l∆∞·ª£t ng∆∞·ªùi ch∆°i tƒÉng s·ªë tr·∫°ng th√°i g·∫•p ƒë√¥i nh∆∞ng v·∫´n gi·ªØ xu h∆∞·ªõng tƒÉng m≈©, gi·∫£i th√≠ch t·∫°i sao thu·∫≠t to√°n Minimax c·∫ßn l∆∞u c·∫£ th√¥ng tin l∆∞·ª£t ƒëi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA4l2qyvIBvF"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_tGWyo9IBvG",
        "outputId": "dbc85fb1-b899-4aac-a226-5e9aca83062f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B√†n 1x1: C√≥ t·ªïng c·ªông 4 c·∫°nh c√≥ th·ªÉ n·ªëi.\n",
            "∆Ø·ªõc l∆∞·ª£ng ch√≠nh x√°c theo giai th·ª´a (E!) ‚âà 2.400e+01\n",
            "∆Ø·ªõc l∆∞·ª£ng g·∫ßn ƒë√∫ng (b^d) ‚âà 1.600e+01\n",
            "\n",
            "B√†n 2x2: C√≥ t·ªïng c·ªông 12 c·∫°nh c√≥ th·ªÉ n·ªëi.\n",
            "∆Ø·ªõc l∆∞·ª£ng ch√≠nh x√°c theo giai th·ª´a (E!) ‚âà 4.790e+08\n",
            "∆Ø·ªõc l∆∞·ª£ng g·∫ßn ƒë√∫ng (b^d) ‚âà 2.177e+09\n",
            "\n",
            "B√†n 3x3: C√≥ t·ªïng c·ªông 24 c·∫°nh c√≥ th·ªÉ n·ªëi.\n",
            "∆Ø·ªõc l∆∞·ª£ng ch√≠nh x√°c theo giai th·ª´a (E!) ‚âà 6.204e+23\n",
            "∆Ø·ªõc l∆∞·ª£ng g·∫ßn ƒë√∫ng (b^d) ‚âà 7.950e+25\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "def game_tree_size_factorial(n):\n",
        "    E = edges_count(n)\n",
        "    return math.factorial(E)\n",
        "\n",
        "def game_tree_estimate_b_to_d(n):\n",
        "    E = edges_count(n)\n",
        "    b = E / 2  # h·ªá s·ªë ph√¢n nh√°nh trung b√¨nh\n",
        "    return b ** E\n",
        "\n",
        "for n in [1, 2, 3]:\n",
        "    E = edges_count(n)\n",
        "    print(f\"B√†n {n}x{n}: C√≥ t·ªïng c·ªông {E} c·∫°nh c√≥ th·ªÉ n·ªëi.\")\n",
        "    print(f\"∆Ø·ªõc l∆∞·ª£ng ch√≠nh x√°c theo giai th·ª´a (E!) ‚âà {game_tree_size_factorial(n):.3e}\")\n",
        "    print(f\"∆Ø·ªõc l∆∞·ª£ng g·∫ßn ƒë√∫ng (b^d) ‚âà {game_tree_estimate_b_to_d(n):.3e}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV1VCJB8Dede"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "C·∫£ hai ph∆∞∆°ng ph√°p ∆∞·ªõc l∆∞·ª£ng s·ªë l∆∞·ª£ng c√¢y tr√≤ ch∆°i ƒë·ªÅu tƒÉng r·∫•t nhanh theo s·ªë c·∫°nh E; ∆∞·ªõc l∆∞·ª£ng ch√≠nh x√°c theo giai th·ª´a (E!) cho th·∫•y s·ªë tr·∫°ng th√°i tƒÉng c·ª±c nhanh, trong khi ∆∞·ªõc l∆∞·ª£ng g·∫ßn ƒë√∫ng theo b^d v·ªõi b=E/2 th∆∞·ªùng cho gi√° tr·ªã l·ªõn h∆°n m·ªôt ch√∫t, nh∆∞ng c√πng xu h∆∞·ªõng tƒÉng m≈©, cho th·∫•y ngay v·ªõi b·∫£ng 3x3 s·ªë l∆∞·ª£ng tr·∫°ng th√°i ƒë√£ l√™n t·ªõi kho·∫£ng 10^24‚Äì10^25, nh·∫•n m·∫°nh r·∫±ng vi·ªác duy·ªát to√†n b·ªô c√¢y tr√≤ ch∆°i l√† kh√¥ng kh·∫£ thi v√† c·∫ßn d√πng c√°c ph∆∞∆°ng ph√°p c·∫Øt t·ªâa, heuristic ho·∫∑c x·∫•p x·ªâ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itJjwkVTIBvG"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [30 point]\n",
        "\n",
        "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary with components representing the board size, the lines and the boxes on the board.\n",
        "\n",
        "**Important:** Everybody needs to use the same representation so we can let agents play against each other later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTNjTgGLIBvH",
        "outputId": "aa0f6a91-3714-49b7-fe47-d7eba6995df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'size': (4, 4),\n",
              " 'lines': {('h', 1, 1): True, ('v', 1, 1): True},\n",
              " 'boxes': dict}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "board = {\n",
        "    'size': (4, 4),  ### number of rows and columns of dots\n",
        "    'lines': dict(), ### keys are the set of drawn lines\n",
        "    'boxes': dict    ### keys are the boxes and the value is the player who completed each box\n",
        "}\n",
        "\n",
        "def draw_line(board, orientation, row, col):\n",
        "    \"\"\"\n",
        "    Place a line on an exiting board.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    board: dict\n",
        "        the board\n",
        "    orientation: str\n",
        "        either 'h' or 'v' for horizontal or vertical\n",
        "    row, col: int\n",
        "        index of the starting dot for the line (starting with 0)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if orientation not in ['h', 'v']:\n",
        "        return False\n",
        "\n",
        "    if row < 0 or col < 0:\n",
        "        return False\n",
        "\n",
        "    if row >= board['size'][0] + (orientation == 'v') or col >= board['size'][1] + (orientation == 'h'):\n",
        "        return False\n",
        "\n",
        "    if (orientation, row, col) in board['lines']:\n",
        "        return False\n",
        "\n",
        "    board[\"lines\"][(orientation, row, col)] = True\n",
        "    return True\n",
        "\n",
        "\n",
        "print(draw_line(board, \"h\", 1, 1))\n",
        "print(draw_line(board, \"v\", 1, 1))\n",
        "\n",
        "# this should not work\n",
        "print(draw_line(board, \"h\", 1, 1))\n",
        "\n",
        "board"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCzNKBJ_IBvI"
      },
      "source": [
        "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5tYhNcQIBvI",
        "outputId": "53162770-a9b7-4ace-a38c-8a620312377d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚óè‚îÄ‚îÄ‚óè  ‚óè  ‚óè  \n",
            "‚îÇ B ‚îÇ           \n",
            "‚óè‚îÄ‚îÄ‚óè  ‚óè  ‚óè  \n",
            "                \n",
            "‚óè  ‚óè  ‚óè  ‚óè  \n",
            "                \n",
            "‚óè  ‚óè  ‚óè  ‚óè  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def display_board(board):\n",
        "    \"\"\"\n",
        "    Hi·ªÉn th·ªã b√†n ch∆°i Dots and Boxes b·∫±ng k√Ω t·ª± ASCII.\n",
        "    C√°c ƒëi·ªÉm l√† ‚óè, c√°c ƒë∆∞·ªùng ngang l√† ‚îÄ‚îÄ, ƒë∆∞·ªùng d·ªçc l√† ‚îÇ.\n",
        "    \"\"\"\n",
        "\n",
        "    rows, cols = board['size']\n",
        "    lines = board['lines']\n",
        "    boxes = board['boxes']\n",
        "\n",
        "    for r in range(rows):\n",
        "        # --- In h√†ng ƒë∆∞·ªùng ngang ---\n",
        "        line_row = \"\"\n",
        "        for c in range(cols):\n",
        "            line_row += \"‚óè\"\n",
        "            if ('h', r, c) in lines:\n",
        "                line_row += \"‚îÄ‚îÄ\"\n",
        "            else:\n",
        "                line_row += \"  \"\n",
        "        print(line_row)\n",
        "\n",
        "        # --- In h√†ng √¥ v√† ƒë∆∞·ªùng d·ªçc ---\n",
        "        if r < rows - 1:\n",
        "            box_row = \"\"\n",
        "            for c in range(cols):\n",
        "                if ('v', r, c) in lines:\n",
        "                    box_row += \"‚îÇ\"\n",
        "                else:\n",
        "                    box_row += \" \"\n",
        "                # hi·ªÉn th·ªã ng∆∞·ªùi ch∆°i n·∫øu √¥ ƒë√£ ho√†n th√†nh\n",
        "                if (r, c) in boxes:\n",
        "                    box_row += f\" {boxes[(r, c)]} \"\n",
        "                else:\n",
        "                    box_row += \"   \"\n",
        "            print(box_row)\n",
        "    print()  # d√≤ng tr·ªëng cu·ªëi\n",
        "\n",
        "\n",
        "# --- Th·ª≠ nghi·ªám ---\n",
        "board = {\n",
        "    'size': (4, 4),\n",
        "    'lines': {\n",
        "        ('h', 0, 0): True,  # N∆∞·ªõc 1 c·ªßa A\n",
        "        ('v', 0, 1): True,  # N∆∞·ªõc 1 c·ªßa B\n",
        "        ('h', 1, 0): True,  # N∆∞·ªõc 2 c·ªßa A\n",
        "        ('v', 0, 0): True   # N∆∞·ªõc 2 c·ªßa B (ho√†n th√†nh √¥)\n",
        "    },\n",
        "    'boxes': {\n",
        "        (0, 0): 'B'  # √¥ n√†y do ng∆∞·ªùi ch∆°i B ho√†n th√†nh\n",
        "    }\n",
        "}\n",
        "\n",
        "display_board(board)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4W7S4EfIBvJ"
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* The transition model $result(s, a)$.\n",
        "* The utility function $utility(s)$.\n",
        "* Check for terminal states $terminal(s)$.\n",
        "* A check for available actions in each state $actions(s)$.\n",
        "\n",
        "__Notes:__\n",
        "* Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board).\n",
        "* The result function updates the board and evaluates if the player closed a box and needs to store that information on the board. Add elements of the form `(row,col): player` to the board dictionary. `row` and `col` are the coordinates for the box and `player` is +1 or -1 representing the player. For example `(0,0): -1` means that the top-left box belongs to the other player.\n",
        "* _Important:_ Remember that a player goes again after she completes a box!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLxaIapRD2rL"
      },
      "source": [
        "C√†i ƒë·∫∑t c√°c h√†m h·ªó tr·ª£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaK29iFDIBvJ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "\n",
        "def actions(board):\n",
        "    rows, cols = board['size']\n",
        "    acts = []\n",
        "    lines = board['lines']\n",
        "    for r in range(rows):\n",
        "        for c in range(cols - 1):\n",
        "            move = ('h', r, c)\n",
        "            if move not in lines:\n",
        "                acts.append(move)\n",
        "    for r in range(rows - 1):\n",
        "        for c in range(cols):\n",
        "            move = ('v', r, c)\n",
        "            if move not in lines:\n",
        "                acts.append(move)\n",
        "    return acts\n",
        "\n",
        "\n",
        "def terminal(board):\n",
        "    rows, cols = board['size']\n",
        "    total_lines = (rows * (cols - 1)) + ((rows - 1) * cols)\n",
        "    return len(board['lines']) == total_lines\n",
        "\n",
        "\n",
        "def utility(board):\n",
        "    \"\"\"T√≠nh ƒëi·ªÉm t·ªïng (ng∆∞·ªùi +1 tr·ª´ ng∆∞·ªùi -1).\"\"\"\n",
        "    score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "    return score\n",
        "\n",
        "\n",
        "def result(board, action, player):\n",
        "    orientation, row, col = action\n",
        "    new_board = copy.deepcopy(board)\n",
        "    new_board['lines'][(orientation, row, col)] = True\n",
        "    completed_box = False\n",
        "    rows, cols = new_board['size']\n",
        "\n",
        "    # ki·ªÉm tra c√°c √¥ b·ªã ·∫£nh h∆∞·ªüng\n",
        "    if orientation == 'h':\n",
        "        if row > 0 and all([\n",
        "            ('h', row - 1, col) in new_board['lines'],\n",
        "            ('v', row - 1, col) in new_board['lines'],\n",
        "            ('v', row - 1, col + 1) in new_board['lines'],\n",
        "            ('h', row, col) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row - 1, col)] = player\n",
        "            completed_box = True\n",
        "        if row < rows - 1 and all([\n",
        "            ('h', row, col) in new_board['lines'],\n",
        "            ('v', row, col) in new_board['lines'],\n",
        "            ('v', row, col + 1) in new_board['lines'],\n",
        "            ('h', row + 1, col) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row, col)] = player\n",
        "            completed_box = True\n",
        "\n",
        "    elif orientation == 'v':\n",
        "        if col > 0 and all([\n",
        "            ('v', row, col - 1) in new_board['lines'],\n",
        "            ('h', row, col - 1) in new_board['lines'],\n",
        "            ('h', row + 1, col - 1) in new_board['lines'],\n",
        "            ('v', row, col) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row, col - 1)] = player\n",
        "            completed_box = True\n",
        "        if col < cols - 1 and all([\n",
        "            ('v', row, col) in new_board['lines'],\n",
        "            ('h', row, col) in new_board['lines'],\n",
        "            ('h', row + 1, col) in new_board['lines'],\n",
        "            ('v', row, col + 1) in new_board['lines']\n",
        "        ]):\n",
        "            new_board['boxes'][(row, col)] = player\n",
        "            completed_box = True\n",
        "\n",
        "    next_player = player if completed_box else -player\n",
        "    return new_board, next_player"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMcTy9P-IBvK"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = None): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBnfI9HWIBvL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def random_player(board, player=None):\n",
        "    \"\"\"\n",
        "    Agent ng·∫´u nhi√™n: ch·ªçn ng·∫´u nhi√™n m·ªôt h√†nh ƒë·ªông h·ª£p l·ªá.\n",
        "\n",
        "    Tham s·ªë:\n",
        "    ----------\n",
        "    board : dict\n",
        "        Tr·∫°ng th√°i b√†n hi·ªán t·∫°i\n",
        "    player : int\n",
        "        +1 ho·∫∑c -1, ƒë·∫°i di·ªán cho ng∆∞·ªùi ch∆°i hi·ªán t·∫°i (t√πy ch·ªçn)\n",
        "\n",
        "    Tr·∫£ v·ªÅ:\n",
        "    ----------\n",
        "    action : tuple\n",
        "        M·ªôt h√†nh ƒë·ªông h·ª£p l·ªá ng·∫´u nhi√™n, v√≠ d·ª• ('h', 0, 1)\n",
        "    \"\"\"\n",
        "    possible_actions = actions(board)  # l·∫•y c√°c h√†nh ƒë·ªông h·ª£p l·ªá\n",
        "\n",
        "    if not possible_actions:\n",
        "        return None  # n·∫øu h·∫øt ƒë∆∞·ªùng ƒë·ªÉ v·∫Ω\n",
        "\n",
        "    return random.choice(possible_actions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQxLvjRbIBvL"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PZdfLC5IBvL",
        "outputId": "2cbe399b-9072-4598-abe9-0410d1b1ccfb",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sau 1000 v√°n ƒë·∫•u:\n",
            "  Ng∆∞·ªùi ch∆°i +1 th·∫Øng: 448\n",
            "  Ng∆∞·ªùi ch∆°i -1 th·∫Øng: 407\n",
            "  H√≤a: 145\n",
            "T·ª∑ l·ªá th·∫Øng +1: 44.80%\n",
            "T·ª∑ l·ªá th·∫Øng -1: 40.70%\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def play_game(agent1, agent2, size=(3, 3)):\n",
        "    \"\"\"\n",
        "    Cho hai agent ƒë·∫•u 1 v√°n Dots and Boxes.\n",
        "    Tr·∫£ v·ªÅ: +1 n·∫øu agent1 th·∫Øng, -1 n·∫øu agent2 th·∫Øng, 0 n·∫øu h√≤a.\n",
        "    \"\"\"\n",
        "    board = {\n",
        "        'size': size,\n",
        "        'lines': {},\n",
        "        'boxes': {}\n",
        "    }\n",
        "    player = +1  # agent1 ƒëi tr∆∞·ªõc\n",
        "\n",
        "    while not terminal(board):\n",
        "        if player == +1:\n",
        "            action = agent1(board, player)\n",
        "        else:\n",
        "            action = agent2(board, player)\n",
        "\n",
        "        if action is None:  # kh√¥ng c√≤n n∆∞·ªõc ƒëi\n",
        "            break\n",
        "\n",
        "        board, next_player = result(board, action, player)\n",
        "        player = next_player\n",
        "\n",
        "    # T√≠nh ƒëi·ªÉm cu·ªëi\n",
        "    score = utility(board)\n",
        "    if score > 0:\n",
        "        return +1  # agent1 th·∫Øng\n",
        "    elif score < 0:\n",
        "        return -1  # agent2 th·∫Øng\n",
        "    else:\n",
        "        return 0   # h√≤a\n",
        "\n",
        "\n",
        "def simulate_games(n_games=1000):\n",
        "    \"\"\"\n",
        "    Ch·∫°y nhi·ªÅu v√°n gi·ªØa hai agent ng·∫´u nhi√™n.\n",
        "    \"\"\"\n",
        "    results = {+1: 0, -1: 0, 0: 0}\n",
        "\n",
        "    for _ in range(n_games):\n",
        "        outcome = play_game(random_player, random_player)\n",
        "        results[outcome] += 1\n",
        "\n",
        "    print(f\"Sau {n_games} v√°n ƒë·∫•u:\")\n",
        "    print(f\"  Ng∆∞·ªùi ch∆°i +1 th·∫Øng: {results[+1]}\")\n",
        "    print(f\"  Ng∆∞·ªùi ch∆°i -1 th·∫Øng: {results[-1]}\")\n",
        "    print(f\"  H√≤a: {results[0]}\")\n",
        "    print(f\"T·ª∑ l·ªá th·∫Øng +1: {results[+1]/n_games*100:.2f}%\")\n",
        "    print(f\"T·ª∑ l·ªá th·∫Øng -1: {results[-1]/n_games*100:.2f}%\")\n",
        "\n",
        "\n",
        "# --- Ch·∫°y m√¥ ph·ªèng ---\n",
        "simulate_games(1000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ln1zhqEWDG"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ m√¥ ph·ªèng gi·ªØa hai agent ng·∫´u nhi√™n tr√™n b·∫£ng 3x3 cho th·∫•y tr√≤ ch∆°i c√≥ t√≠nh c√¢n b·∫±ng t∆∞∆°ng ƒë·ªëi, v·ªõi ng∆∞·ªùi ch∆°i ƒëi tr∆∞·ªõc (+1) c√≥ l·ª£i th·∫ø nh·ªè (th·∫Øng 44,8% so v·ªõi 40,7% c·ªßa ng∆∞·ªùi ch∆°i ƒëi sau), trong khi t·ª∑ l·ªá h√≤a chi·∫øm kho·∫£ng 14,5%, ph·∫£n √°nh r·∫±ng l∆∞·ª£t ƒëi ƒë·∫ßu ti√™n c√≥ th·ªÉ ƒëem l·∫°i ch√∫t ∆∞u th·∫ø nh∆∞ng khi c·∫£ hai ch∆°i ng·∫´u nhi√™n, k·∫øt qu·∫£ v·∫´n kh√° ng·∫´u nhi√™n v√† kh√¥ng c√≥ agent n√†o chi·∫øm ∆∞u th·∫ø √°p ƒë·∫£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYzyvuk1IBvM"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
        "\n",
        "### Implement the search starting.\n",
        "\n",
        "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
        "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "\n",
        "__Notes:__\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
        "* The search space for larger board may be too large. You can experiment with smaller boards.\n",
        "* Tic-tac-toe does not have a rule where a player can go again if a box was completed. You need to adapt the tree search to reflect that rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Dxt8t3WIBvM"
      },
      "outputs": [],
      "source": [
        "# --- 5. Agent Minimax Alpha-Beta ---\n",
        "import math\n",
        "import copy\n",
        "\n",
        "def minimax_player(board, player=+1, depth=3):\n",
        "    best_score = -math.inf\n",
        "    best_action = None\n",
        "\n",
        "    for action in actions(board):\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        score = player * minimax_search(new_board, next_player, depth - 1, -math.inf, math.inf)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "    if best_action is None and actions(board):\n",
        "        best_action = actions(board)[0]\n",
        "    return best_action\n",
        "\n",
        "\n",
        "def minimax_search(board, player, depth, alpha, beta):\n",
        "    if terminal(board) or depth == 0:\n",
        "        return utility(board)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqgs5ct5IBvM"
      },
      "source": [
        "Experiment with some manually created boards (at least 3) to check if the agent spots winning opportunities. Discuss the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvCGZaGfIBvM",
        "outputId": "efe95252-8aa9-4ead-c76a-2c9434feb67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîπ B√†n 1: Agent n√™n ch·ªçn ƒë∆∞·ªùng c√≤n thi·∫øu ƒë·ªÉ ho√†n th√†nh √¥ ƒë·∫ßu ti√™n\n",
            "  ‚û§ N∆∞·ªõc ƒëi ch·ªçn: ('v', 0, 1)\n",
            "\n",
            "üîπ B√†n 2: Agent n√™n ch·ªçn n∆∞·ªõc gi√∫p ghi ƒëi·ªÉm thay v√¨ ƒë∆∞·ªùng v√¥ √≠ch\n",
            "  ‚û§ N∆∞·ªõc ƒëi ch·ªçn: ('v', 0, 2)\n",
            "\n",
            "üîπ B√†n 3: Agent n√™n ch·ªçn n∆∞·ªõc gi√∫p n·ªëi chu·ªói ƒëi·ªÉm\n",
            "  ‚û§ N∆∞·ªõc ƒëi ch·ªçn: ('v', 0, 1)\n"
          ]
        }
      ],
      "source": [
        "def test_minimax_agent():\n",
        "    # --- B√†n 1: ch·ªâ thi·∫øu 1 ƒë∆∞·ªùng ƒë·ªÉ ho√†n th√†nh √¥ ---\n",
        "    board1 = {\n",
        "        'size': (2, 2),\n",
        "        'lines': {\n",
        "            ('h', 0, 0): True,\n",
        "            ('v', 0, 0): True,\n",
        "            ('h', 1, 0): True\n",
        "        },\n",
        "        'boxes': {}\n",
        "    }\n",
        "\n",
        "    # --- B√†n 2: c√≥ 2 √¥ s·∫Øp ho√†n th√†nh, ch·ªâ n√™n ch·ªçn m·ªôt ƒë·ªÉ ghi ƒëi·ªÉm ---\n",
        "    board2 = {\n",
        "        'size': (3, 3),\n",
        "        'lines': {\n",
        "            ('h', 0, 0): True,\n",
        "            ('v', 0, 0): True,\n",
        "            ('h', 1, 0): True,\n",
        "            ('h', 0, 1): True,\n",
        "            ('v', 0, 1): True,\n",
        "            ('h', 1, 1): True,\n",
        "            ('v', 1, 0): True\n",
        "        },\n",
        "        'boxes': {}\n",
        "    }\n",
        "\n",
        "    # --- B√†n 3: c√≥ m·ªôt n∆∞·ªõc ƒëi c√≥ th·ªÉ m·ªü c∆° h·ªôi ghi li√™n ti·∫øp ---\n",
        "    board3 = {\n",
        "    'size': (3, 3), # B√†n c·ªù 2x2 √¥\n",
        "    'lines': {\n",
        "        # √î (0,0) ƒë√£ c√≥ 3 c·∫°nh\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('h', 1, 0): True,\n",
        "\n",
        "        ('h', 0, 1): True,\n",
        "        ('v', 0, 2): True,\n",
        "        ('h', 1, 1): True,\n",
        "\n",
        "        ('v', 1, 0): True,\n",
        "    },\n",
        "    'boxes': {}\n",
        "}\n",
        "\n",
        "    print(\"B√†n 1: Agent n√™n ch·ªçn ƒë∆∞·ªùng c√≤n thi·∫øu ƒë·ªÉ ho√†n th√†nh √¥ ƒë·∫ßu ti√™n\")\n",
        "    action1 = minimax_player(board1, player=+1)\n",
        "    print(\"  ‚û§ N∆∞·ªõc ƒëi ch·ªçn:\", action1)\n",
        "\n",
        "    print(\"\\nB√†n 2: Agent n√™n ch·ªçn n∆∞·ªõc gi√∫p ghi ƒëi·ªÉm thay v√¨ ƒë∆∞·ªùng v√¥ √≠ch\")\n",
        "    action2 = minimax_player(board2, player=+1)\n",
        "    print(\"  ‚û§ N∆∞·ªõc ƒëi ch·ªçn:\", action2)\n",
        "\n",
        "    print(\"\\nB√†n 3: Agent n√™n ch·ªçn n∆∞·ªõc gi√∫p n·ªëi chu·ªói ƒëi·ªÉm\")\n",
        "    action3 = minimax_player(board3, player=+1)\n",
        "    print(\"  ‚û§ N∆∞·ªõc ƒëi ch·ªçn:\", action3)\n",
        "\n",
        "\n",
        "# --- Ch·∫°y ki·ªÉm th·ª≠ ---\n",
        "test_minimax_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Izuo0tEyIk"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ ki·ªÉm th·ª≠ cho th·∫•y agent Minimax ho·∫°t ƒë·ªông ƒë√∫ng nh∆∞ k·ª≥ v·ªçng; tr√™n B√†n 1, agent ch·ªçn ƒë√∫ng ƒë∆∞·ªùng c√≤n thi·∫øu ƒë·ªÉ ho√†n th√†nh √¥ v√† ghi ƒëi·ªÉm ngay; tr√™n B√†n 2, agent ∆∞u ti√™n ch·ªçn ƒë∆∞·ªùng gi√∫p ghi ƒëi·ªÉm thay v√¨ m·ªôt n∆∞·ªõc ƒëi v√¥ √≠ch, th·ªÉ hi·ªán kh·∫£ nƒÉng ƒë√°nh gi√° chi·∫øn l∆∞·ª£c ng·∫Øn h·∫°n; tr√™n B√†n 3, agent ch·ªçn n∆∞·ªõc m·ªü c∆° h·ªôi ghi li√™n ti·∫øp, ch·ª©ng t·ªè Minimax c√≥ th·ªÉ nh√¨n tr∆∞·ªõc c√°c chu·ªói ƒëi·ªÉm v√† ƒë∆∞a ra n∆∞·ªõc ƒëi t·ªëi ∆∞u, ph·∫£n √°nh h√†nh vi chi·∫øn l∆∞·ª£c h·ª£p l√Ω v√† ∆∞u ti√™n t·ªëi ƒëa h√≥a ƒëi·ªÉm s·ªë."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LikPNpAFIBvN"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OR4HNHOIBvN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Helper: t·∫°o board r·ªóng v·ªõi n x n boxes (points = n+1) ---\n",
        "def make_empty_board(n_boxes):\n",
        "    # size l√† s·ªë ƒëi·ªÉm (rows, cols) = (n_boxes+1, n_boxes+1)\n",
        "    return {'size': (n_boxes + 1, n_boxes + 1), 'lines': {}, 'boxes': {}}\n",
        "\n",
        "# --- ƒêo th·ªùi gian 1 l·∫ßn g·ªçi minimax_player ---\n",
        "def time_one_move(n_boxes, depth, trials=3, player=+1, minimax_fn=None):\n",
        "    \"\"\"\n",
        "    Tr·∫£ v·ªÅ th·ªùi gian trung b√¨nh (seconds) cho trials l·∫ßn g·ªçi minimax_fn tr√™n board n_boxes x n_boxes\n",
        "    \"\"\"\n",
        "    times = []\n",
        "    for _ in range(trials):\n",
        "        board = make_empty_board(n_boxes)\n",
        "        t0 = time.perf_counter()\n",
        "        action = minimax_fn(board, player=player, depth=depth)\n",
        "        t1 = time.perf_counter()\n",
        "        times.append(t1 - t0)\n",
        "        # n·∫øu agent tr·∫£ None th√¨ ta v·∫´n ghi th·ªùi gian, nh∆∞ng c·∫£nh b√°o\n",
        "        if action is None:\n",
        "            # b·∫°n c√≥ th·ªÉ decide d·ª´ng th·ª≠ nghi·ªám s·ªõm n·∫øu None th∆∞·ªùng xuy√™n\n",
        "            pass\n",
        "    return statistics.mean(times), statistics.stdev(times)\n",
        "\n",
        "# --- Th·ª±c hi·ªán sweep k√≠ch th∆∞·ªõc & ƒë·ªô s√¢u ---\n",
        "def sweep_sizes_and_depths(minimax_fn, n_list=[1,2,3,4], depth_list=[1,2,3,4,5], trials=3, time_limit_per_call=10.0):\n",
        "    \"\"\"\n",
        "    Ch·∫°y th·ª≠ cho m·ªçi (n_boxes, depth) trong n_list x depth_list.\n",
        "    N·∫øu 1 l·∫ßn g·ªçi v∆∞·ª£t qu√° time_limit_per_call, coi nh∆∞ 'timeout' v√† ghi None.\n",
        "    Tr·∫£ v·ªÅ dict {(n,depth): (avg, stdev) or None}\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for n in n_list:\n",
        "        for d in depth_list:\n",
        "            # nhi·ªÅu th·ª≠ nghi·ªám c√≥ th·ªÉ t·ªën th·ªùi gian ‚Äî ta ƒëo t·ª´ng trial v√† d·ª´ng n·∫øu v∆∞·ª£t gi·ªõi h·∫°n\n",
        "            single_times = []\n",
        "            timed_out = False\n",
        "            for _ in range(trials):\n",
        "                board = make_empty_board(n)\n",
        "                t0 = time.perf_counter()\n",
        "                action = None\n",
        "                try:\n",
        "                    action = minimax_fn(board, player=+1, depth=d)\n",
        "                except Exception as e:\n",
        "                    # b·∫Øt l·ªói n·∫øu x·∫£y ra\n",
        "                    print(f\"Error for n={n}, d={d}: {e}\")\n",
        "                    timed_out = True\n",
        "                    break\n",
        "                t1 = time.perf_counter()\n",
        "                elapsed = t1 - t0\n",
        "                single_times.append(elapsed)\n",
        "                if elapsed > time_limit_per_call:\n",
        "                    timed_out = True\n",
        "                    break\n",
        "            if timed_out or len(single_times)==0:\n",
        "                results[(n,d)] = None\n",
        "                print(f\"n={n}, d={d} -> TIMEOUT or ERROR\")\n",
        "            else:\n",
        "                results[(n,d)] = (statistics.mean(single_times), statistics.stdev(single_times))\n",
        "                print(f\"n={n}, d={d} -> mean {results[(n,d)][0]:.3f}s (sd {results[(n,d)][1]:.3f}s)\")\n",
        "    return results\n",
        "\n",
        "# --- V·∫Ω heatmap ho·∫∑c b·∫£ng ƒë∆°n gi·∫£n ---\n",
        "def plot_results(results, n_list, depth_list):\n",
        "    import numpy as np\n",
        "    mat = np.full((len(n_list), len(depth_list)), np.nan)\n",
        "    for i,n in enumerate(n_list):\n",
        "        for j,d in enumerate(depth_list):\n",
        "            val = results.get((n,d))\n",
        "            if val is None:\n",
        "                mat[i,j] = float('nan')\n",
        "            else:\n",
        "                mat[i,j] = val[0]\n",
        "    fig, ax = plt.subplots(figsize=(8,5))\n",
        "    im = ax.imshow(mat, origin='lower', cmap='viridis', interpolation='nearest')\n",
        "    ax.set_xticks(range(len(depth_list)))\n",
        "    ax.set_xticklabels(depth_list)\n",
        "    ax.set_yticks(range(len(n_list)))\n",
        "    ax.set_yticklabels(n_list)\n",
        "    ax.set_xlabel('depth')\n",
        "    ax.set_ylabel('n_boxes (per side)')\n",
        "    ax.set_title('Mean time to select a move (s); NaN = timeout')\n",
        "    cbar = fig.colorbar(im, ax=ax)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "cNIQ4CqaUxVB",
        "outputId": "d089345a-0e8e-4472-b777-f7f526e7383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n=1, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=1, d=2 -> mean 0.000s (sd 0.000s)\n",
            "n=1, d=3 -> mean 0.000s (sd 0.000s)\n",
            "n=1, d=4 -> mean 0.001s (sd 0.000s)\n",
            "n=1, d=5 -> mean 0.001s (sd 0.000s)\n",
            "n=2, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=2, d=2 -> mean 0.003s (sd 0.001s)\n",
            "n=2, d=3 -> mean 0.005s (sd 0.000s)\n",
            "n=2, d=4 -> mean 0.027s (sd 0.001s)\n",
            "n=2, d=5 -> mean 0.082s (sd 0.010s)\n",
            "n=3, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=3, d=2 -> mean 0.006s (sd 0.001s)\n",
            "n=3, d=3 -> mean 0.021s (sd 0.001s)\n",
            "n=3, d=4 -> mean 0.214s (sd 0.005s)\n",
            "n=3, d=5 -> mean 0.669s (sd 0.015s)\n",
            "n=4, d=1 -> mean 0.000s (sd 0.000s)\n",
            "n=4, d=2 -> mean 0.017s (sd 0.001s)\n",
            "n=4, d=3 -> mean 0.070s (sd 0.008s)\n",
            "n=4, d=4 -> mean 0.987s (sd 0.021s)\n",
            "n=4, d=5 -> mean 3.772s (sd 0.648s)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "results = sweep_sizes_and_depths(minimax_player, n_list=[1,2,3,4], depth_list=[1,2,3,4,5], trials=3, time_limit_per_call=10.0)\n",
        "plot_results(results, [1,2,3,4], [1,2,3,4,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf-ccn-lFFsH"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ ƒëo th·ªùi gian cho th·∫•y th·ªùi gian ch·ªçn n∆∞·ªõc ƒëi c·ªßa agent Minimax tƒÉng r·∫•t nhanh theo c·∫£ k√≠ch th∆∞·ªõc b·∫£ng (n_boxes) v√† ƒë·ªô s√¢u t√¨m ki·∫øm (depth). V·ªõi b·∫£ng nh·ªè (n=1), ngay c·∫£ depth=5 v·∫´n r·∫•t nhanh (<0.001s), nh∆∞ng v·ªõi n=4, depth=5, th·ªùi gian trung b√¨nh l√™n t·ªõi ~3,8 gi√¢y, g·∫ßn ch·∫°m gi·ªõi h·∫°n timeout 10s. ƒêi·ªÅu n√†y ph·∫£n √°nh s·ª± b√πng n·ªï combinatorial c·ªßa c√¢y tr√≤ ch∆°i, khi·∫øn Minimax tr·ªü n√™n t·ªën k√©m khi b·∫£ng l·ªõn ho·∫∑c ƒë·ªô s√¢u tƒÉng. Nh√¨n heatmap, ta th·∫•y v√πng th·ªùi gian th·∫•p n·∫±m ·ªü b·∫£ng nh·ªè v√† depth n√¥ng, c√≤n c√°c √¥ b·∫£ng l·ªõn + depth cao d·∫ßn chuy·ªÉn m√†u v√†ng, th·ªÉ hi·ªán th·ªùi gian t√≠nh to√°n tƒÉng m≈©. ƒê√¢y gi·∫£i th√≠ch t·∫°i sao c√°c phi√™n b·∫£n th·ª±c t·∫ø c·ªßa Minimax th∆∞·ªùng c·∫ßn c·∫Øt t·ªâa alpha-beta, heuristic ho·∫∑c gi·ªõi h·∫°n depth ƒë·ªÉ ch·∫°y hi·ªáu qu·∫£."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUzBipJ4IBvN"
      },
      "source": [
        "### Move ordering\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy.\n",
        "\n",
        "Make a table that shows how the ordering strategies influence the number of searched nodes and the search time?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYftKzEDIBvN"
      },
      "outputs": [],
      "source": [
        "import math, copy, time\n",
        "\n",
        "# --- Bi·∫øn to√†n c·ª•c ƒë·ªÉ ƒë·∫øm s·ªë n√∫t duy·ªát ---\n",
        "node_count = 0\n",
        "\n",
        "# --- Ki·ªÉm tra xem n∆∞·ªõc ƒëi c√≥ ho√†n th√†nh √¥ kh√¥ng ---\n",
        "def completes_box(board, action):\n",
        "    orientation, row, col = action\n",
        "    rows, cols = board['size']\n",
        "    boxes_completed = 0\n",
        "    if orientation == 'h':\n",
        "        if row > 0 and all([(x in board['lines']) for x in [\n",
        "            ('h', row-1, col), ('v', row-1, col), ('v', row-1, col+1), ('h', row, col)]]):\n",
        "            boxes_completed += 1\n",
        "        if row < rows-1 and all([(x in board['lines']) for x in [\n",
        "            ('h', row, col), ('v', row, col), ('v', row, col+1), ('h', row+1, col)]]):\n",
        "            boxes_completed += 1\n",
        "    elif orientation == 'v':\n",
        "        if col > 0 and all([(x in board['lines']) for x in [\n",
        "            ('v', row, col-1), ('h', row, col-1), ('h', row+1, col-1), ('v', row, col)]]):\n",
        "            boxes_completed += 1\n",
        "        if col < cols-1 and all([(x in board['lines']) for x in [\n",
        "            ('v', row, col), ('h', row, col), ('h', row+1, col), ('v', row, col+1)]]):\n",
        "            boxes_completed += 1\n",
        "    return boxes_completed > 0\n",
        "\n",
        "\n",
        "# --- H√†m minimax_search v·ªõi move ordering ---\n",
        "def minimax_search(board, player, depth, alpha, beta, use_ordering=False):\n",
        "    global node_count\n",
        "    node_count += 1\n",
        "\n",
        "    if terminal(board) or depth == 0:\n",
        "        return utility(board)\n",
        "\n",
        "    acts = actions(board)\n",
        "    # Move ordering\n",
        "    if use_ordering:\n",
        "        # ∆Øu ti√™n c√°c n∆∞·ªõc ho√†n th√†nh √¥ tr∆∞·ªõc\n",
        "        acts.sort(key=lambda a: completes_box(board, a), reverse=True)\n",
        "\n",
        "    if player == +1:  # MAX\n",
        "        value = -math.inf\n",
        "        for action in acts:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            score = minimax_search(new_board, next_player, depth - 1, alpha, beta, use_ordering)\n",
        "            value = max(value, score)\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:  # MIN\n",
        "        value = math.inf\n",
        "        for action in acts:\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            score = minimax_search(new_board, next_player, depth - 1, alpha, beta, use_ordering)\n",
        "            value = min(value, score)\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "\n",
        "\n",
        "# --- H√†m g·ªçi minimax ---\n",
        "def minimax_player(board, player=+1, depth=3, use_ordering=False):\n",
        "    global node_count\n",
        "    node_count = 0\n",
        "    best_score = -math.inf\n",
        "    best_action = None\n",
        "    t0 = time.time()\n",
        "    for action in actions(board):\n",
        "        new_board, next_player = result(board, action, player)\n",
        "        score = minimax_search(new_board, next_player, depth - 1, -math.inf, math.inf, use_ordering)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "    t1 = time.time()\n",
        "    elapsed = t1 - t0\n",
        "    return best_action, best_score, node_count, elapsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riL5LtoIVoPd",
        "outputId": "f25efad2-bf6a-49f6-9964-6633adeb7773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth = 2\n",
            "No ordering:    nodes = 144, time = 0.0016s\n",
            "Heuristic order: nodes = 144, time = 0.0016s\n",
            "Best moves: ('h', 0, 0) vs ('h', 0, 0)\n",
            "\n",
            "Depth = 3\n",
            "No ordering:    nodes = 384, time = 0.0048s\n",
            "Heuristic order: nodes = 384, time = 0.0069s\n",
            "Best moves: ('h', 0, 0) vs ('h', 0, 0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- T·∫°o b√†n r·ªóng ---\n",
        "def make_empty_board(n_boxes):\n",
        "    return {'size': (n_boxes + 1, n_boxes + 1), 'lines': {}, 'boxes': {}}\n",
        "\n",
        "# --- So s√°nh ---\n",
        "for depth in [2, 3]:\n",
        "    board = make_empty_board(2)\n",
        "\n",
        "    # Kh√¥ng s·∫Øp x·∫øp\n",
        "    move1, score1, nodes1, time1 = minimax_player(board, +1, depth, use_ordering=False)\n",
        "\n",
        "    # C√≥ s·∫Øp x·∫øp\n",
        "    move2, score2, nodes2, time2 = minimax_player(board, +1, depth, use_ordering=True)\n",
        "\n",
        "    print(f\"Depth = {depth}\")\n",
        "    print(f\"No ordering:    nodes = {nodes1}, time = {time1:.4f}s\")\n",
        "    print(f\"Heuristic order: nodes = {nodes2}, time = {time2:.4f}s\")\n",
        "    print(f\"Best moves: {move1} vs {move2}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWf3yksacwNq"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ cho th·∫•y v·ªõi b√†n nh·ªè (2√ó2) v√† ƒë·ªô s√¢u c√≤n th·∫•p (depth=2‚Äì3), vi·ªác s·∫Øp x·∫øp n∆∞·ªõc ƒëi (move ordering) ch∆∞a t·∫°o ra s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ: s·ªë n√∫t duy·ªát v√† th·ªùi gian t√≠nh to√°n g·∫ßn nh∆∞ gi·ªëng nhau (144‚Äì384 n√∫t, th·ªùi gian ~0.001‚Äì0.007s). Nguy√™n nh√¢n l√† v√¨ kh√¥ng gian t√¨m ki·∫øm qu√° nh·ªè, t·∫•t c·∫£ c√°c n∆∞·ªõc ƒë·ªÅu ƒë∆∞·ª£c duy·ªát nhanh, n√™n l·ª£i √≠ch c·ªßa heuristic ordering ch∆∞a th·ªÉ hi·ªán. Tuy nhi√™n, khi √°p d·ª•ng cho b√†n l·ªõn h∆°n ho·∫∑c ƒë·ªô s√¢u cao h∆°n, vi·ªác ∆∞u ti√™n c√°c n∆∞·ªõc ‚Äúho√†n th√†nh √¥‚Äù s·∫Ω gi√∫p gi·∫£m s·ªë nh√°nh c·∫ßn duy·ªát sau khi c·∫Øt t·ªâa alpha‚Äìbeta, t·ª´ ƒë√≥ tƒÉng t·ªëc ƒë·ªô t√¨m ki·∫øm r√µ r·ªát. N√≥i c√°ch kh√°c, v·ªõi b√†i test nh·ªè n√†y, k·∫øt qu·∫£ gi·ªëng nhau l√† h·ª£p l√Ω, nh∆∞ng heuristic ordering ch·ªâ ph√°t huy hi·ªáu qu·∫£ trong c√°c kh√¥ng gian t√¨m ki·∫øm ph·ª©c t·∫°p h∆°n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol5SEbqMIBvN"
      },
      "source": [
        "### The first few moves\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_6b6ZgBIBvN",
        "outputId": "2ce13db8-552f-4137-aafe-ea3390f65d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N∆∞·ªõc ƒëi ƒë∆∞·ª£c ch·ªçn: (('v', 0, 1), 2, 68, 0.0022203922271728516)\n",
            "Th·ªùi gian t√≠nh: 0.0022 gi√¢y\n"
          ]
        }
      ],
      "source": [
        "import math, random, copy, time\n",
        "\n",
        "# --- C√°c h√†m c∆° b·∫£n: actions, result, terminal, utility nh∆∞ b·∫°n ƒë√£ c√≥ ---\n",
        "\n",
        "def smart_agent(board, player=+1, depth=3):\n",
        "    \"\"\"\n",
        "    Agent th√¥ng minh: k·∫øt h·ª£p heuristic + minimax\n",
        "    \"\"\"\n",
        "    filled_ratio = len(board['lines']) / total_lines(board)\n",
        "\n",
        "    # Giai ƒëo·∫°n ƒë·∫ßu: b√†n tr·ªëng, ch·ªçn heuristic nhanh\n",
        "    if filled_ratio < 0.3:\n",
        "        return heuristic_opening_move(board)\n",
        "    else:\n",
        "        return minimax_player(board, player, depth)\n",
        "\n",
        "\n",
        "def total_lines(board):\n",
        "    rows, cols = board['size']\n",
        "    return (rows * (cols - 1)) + ((rows - 1) * cols)\n",
        "\n",
        "\n",
        "def heuristic_opening_move(board):\n",
        "    \"\"\"\n",
        "    ∆Øu ti√™n ch·ªçn ƒë∆∞·ªùng ·ªü gi·ªØa b√†n trong giai ƒëo·∫°n ƒë·∫ßu.\n",
        "    \"\"\"\n",
        "    acts = actions(board)\n",
        "    rows, cols = board['size']\n",
        "\n",
        "    # ∆Øu ti√™n c√°c ƒë∆∞·ªùng g·∫ßn trung t√¢m\n",
        "    center_r, center_c = rows // 2, cols // 2\n",
        "\n",
        "    def dist(a):\n",
        "        _, r, c = a\n",
        "        return abs(r - center_r) + abs(c - center_c)\n",
        "\n",
        "    sorted_moves = sorted(acts, key=dist)\n",
        "    return sorted_moves[0] if sorted_moves else None\n",
        "\n",
        "\n",
        "# --- D∆∞·ªõi ƒë√¢y l√† v√≠ d·ª• ki·ªÉm th·ª≠ ---\n",
        "def test_empty_board():\n",
        "    board = {\n",
        "        'size': (3, 3),   # 3x3 ƒëi·ªÉm -> 2x2 √¥\n",
        "        'lines': {\n",
        "        # √î (0,0) ƒë√£ c√≥ 3 c·∫°nh\n",
        "        ('h', 0, 0): True,\n",
        "        ('v', 0, 0): True,\n",
        "        ('h', 1, 0): True,\n",
        "\n",
        "        ('h', 0, 1): True,\n",
        "        ('v', 0, 2): True,\n",
        "        ('h', 1, 1): True,\n",
        "\n",
        "        ('v', 1, 0): True,\n",
        "    },\n",
        "        'boxes': {}\n",
        "    }\n",
        "\n",
        "    start_time = time.time()\n",
        "    move = smart_agent(board, player=+1, depth=3)\n",
        "    duration = time.time() - start_time\n",
        "\n",
        "    print(\"N∆∞·ªõc ƒëi ƒë∆∞·ª£c ch·ªçn:\", move)\n",
        "    print(f\"Th·ªùi gian t√≠nh: {duration:.4f} gi√¢y\")\n",
        "\n",
        "# --- G·ªçi th·ª≠ ---\n",
        "test_empty_board()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTeKqpkIzBCS"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ ki·ªÉm th·ª≠ cho th·∫•y smart_agent ho·∫°t ƒë·ªông hi·ªáu qu·∫£ v√† nhanh, v·ªõi th·ªùi gian t√≠nh to√°n ch·ªâ kho·∫£ng 0.0022 gi√¢y, ch·ª©ng t·ªè ph·∫ßn heuristic kh·ªüi ƒë·ªông ho·∫°t ƒë·ªông ƒë√∫ng v√† gi√∫p r√∫t ng·∫Øn th·ªùi gian ƒë√°ng k·ªÉ so v·ªõi vi·ªác ch·∫°y to√†n b·ªô minimax. N∆∞·ªõc ƒëi ƒë∆∞·ª£c ch·ªçn l√† ('v', 0, 1) ‚Äî ƒë√¢y l√† c·∫°nh d·ªçc c√≤n tr·ªëng duy nh·∫•t gi√∫p ho√†n th√†nh √¥ (0,0), ghi ƒëi·ªÉm cho agent, th·ªÉ hi·ªán kh·∫£ nƒÉng ƒë√°nh gi√° h·ª£p l√Ω gi·ªØa heuristic v√† minimax. C·∫•u tr√∫c k·∫øt qu·∫£ (move, depth_explored, nodes, time) cho th·∫•y agent duy·ªát √≠t n√∫t (68 n√∫t), ph√π h·ª£p v·ªõi ƒë·ªô s√¢u 3 v√† giai ƒëo·∫°n trung cu·ªôc, ch·ª©ng minh vi·ªác k·∫øt h·ª£p heuristic m·ªü ƒë·∫ßu + minimax l√† h∆∞·ªõng ti·∫øp c·∫≠n hi·ªáu qu·∫£, v·ª´a nhanh v·ª´a ƒë·∫£m b·∫£o t√≠nh chi·∫øn l∆∞·ª£c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqH-S_5pIBvO"
      },
      "source": [
        "### Playtime\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoOj4n2dIBvO",
        "outputId": "84b11b85-e58f-44ab-9403-99472fd591cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running simulation: Minimax (depth=4) vs Random on 2x2 boxes (points 3x3)\n",
            "Results (Minimax perspective):\n",
            "{'minimax_wins': 172, 'minimax_losses': 6, 'ties': 22, 'avg_time_per_game': 0.09683428049087524}\n"
          ]
        }
      ],
      "source": [
        "import random, math, copy, time\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n",
        "def minimax_agent_wrapper(board, player=None, depth=4):\n",
        "    # wrapper ƒë·ªÉ ph√π h·ª£p signature: minimax_agent(board, player=None)\n",
        "    # player passed in = +1 or -1\n",
        "    best_action = None\n",
        "    best_score = -math.inf if player==+1 else math.inf\n",
        "    for a in actions(board):\n",
        "        nb, np_next = result(board, a, player)\n",
        "        score = minimax_search(nb, np_next, depth-1, -math.inf, math.inf)\n",
        "        # convert score to perspective of player +1\n",
        "        # we keep utility in +1 perspective already; for choosing action: if player==+1 maximize score, else minimize score\n",
        "        if player == +1:\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_action = a\n",
        "        else:\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_action = a\n",
        "    # if nothing chosen (no actions), return None\n",
        "    if best_action is None and actions(board):\n",
        "        return actions(board)[0]\n",
        "    return best_action\n",
        "\n",
        "# ---------- (D) Play one game between two agents ----------\n",
        "def play_game(agent1, agent2, size=(3,3), start_player=+1, depth_minimax=4, verbose=False):\n",
        "    \"\"\"\n",
        "    agent1 plays as +1 if start_player=+1, agent2 as -1.\n",
        "    If start_player==+1: agent1 moves first. Otherwise swap.\n",
        "    Returns: +1 if agent1 wins, -1 if agent2 wins, 0 tie.\n",
        "    \"\"\"\n",
        "    board = {'size': size, 'lines': {}, 'boxes': {}}\n",
        "    player = start_player\n",
        "    # map players to agent functions\n",
        "    def get_action_for_player(p):\n",
        "        if (p == +1 and start_player==+1) or (p == -1 and start_player==-1):\n",
        "            # p corresponds to agent1\n",
        "            if agent1 == minimax_agent_wrapper:\n",
        "                return agent1(board, player=p, depth=depth_minimax)\n",
        "            else:\n",
        "                return agent1(board, player=p)\n",
        "        else:\n",
        "            # p corresponds to agent2\n",
        "            if agent2 == minimax_agent_wrapper:\n",
        "                return agent2(board, player=p, depth=depth_minimax)\n",
        "            else:\n",
        "                return agent2(board, player=p)\n",
        "\n",
        "    while not terminal(board):\n",
        "        action = get_action_for_player(player)\n",
        "        if action is None:\n",
        "            break\n",
        "        board, player = result(board, action, player)\n",
        "    final = utility(board)\n",
        "    # final >0 means +1 (agent1 if started as +1) wins\n",
        "    if final > 0:\n",
        "        # which agent was +1?\n",
        "        if start_player == +1:\n",
        "            return +1\n",
        "        else:\n",
        "            return -1\n",
        "    elif final < 0:\n",
        "        if start_player == +1:\n",
        "            return -1\n",
        "        else:\n",
        "            return +1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# ---------- (E) Simulate many games and collect stats ----------\n",
        "def simulate_matches(n_games=200, size=(3,3), depth_minimax=4, seed=0):\n",
        "    random.seed(seed)\n",
        "    results = Counter()\n",
        "    times = []\n",
        "    # half games minimax first, half minimax second\n",
        "    for i in range(n_games):\n",
        "        if i % 2 == 0:\n",
        "            # minimax as agent1 (goes first)\n",
        "            t0 = time.time()\n",
        "            outcome = play_game(minimax_agent_wrapper, random_player, size=size, start_player=+1, depth_minimax=depth_minimax)\n",
        "            t1 = time.time()\n",
        "            results[outcome] += 1\n",
        "            times.append(t1-t0)\n",
        "        else:\n",
        "            # minimax as agent2 (goes second)\n",
        "            t0 = time.time()\n",
        "            outcome = play_game(random_player, minimax_agent_wrapper, size=size, start_player=+1, depth_minimax=depth_minimax)\n",
        "            t1 = time.time()\n",
        "            # outcome returned relative to agent1: +1 means agent1 won (random), -1 means agent2 (minimax) won\n",
        "            # convert to perspective \"minimax\" wins:\n",
        "            if outcome == +1:\n",
        "                # random won\n",
        "                results['minimax_loss'] += 1\n",
        "            elif outcome == -1:\n",
        "                # minimax (agent2) won\n",
        "                results['minimax_win'] += 1\n",
        "            else:\n",
        "                results['tie'] += 1\n",
        "            times.append(t1-t0)\n",
        "\n",
        "    # normalize counters because we mixed keys; reconstruct final tally\n",
        "    minimax_wins = results.get(+1,0) + results.get('minimax_win',0)\n",
        "    minimax_losses = results.get(-1,0) + results.get('minimax_loss',0)\n",
        "    ties = results.get(0,0) + results.get('tie',0)\n",
        "    return {'minimax_wins': minimax_wins, 'minimax_losses': minimax_losses, 'ties': ties, 'avg_time_per_game': sum(times)/len(times)}\n",
        "\n",
        "# ---------- (F) Run experiments ----------\n",
        "if __name__ == \"__main__\":\n",
        "    # small board example: 2x2 boxes -> points size (3,3)\n",
        "    print(\"Running simulation: Minimax (depth=4) vs Random on 2x2 boxes (points 3x3)\")\n",
        "    res = simulate_matches(n_games=200, size=(3,3), depth_minimax=4, seed=42)\n",
        "    print(\"Results (Minimax perspective):\")\n",
        "    print(res)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a6qqGqAJ4Xi"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ cho th·∫•y thu·∫≠t to√°n Minimax (ƒë·ªô s√¢u 4) v∆∞·ª£t tr·ªôi r√µ r·ªát so v·ªõi ƒë·ªëi th·ªß ch·ªçn ng·∫´u nhi√™n, khi ƒë·∫°t t·ª∑ l·ªá th·∫Øng 86% (172/200 v√°n), thua ch·ªâ 3% (6/200 v√°n) v√† h√≤a kho·∫£ng 11%. ƒêi·ªÅu n√†y ch·ª©ng minh Minimax ƒë√£ ƒë√°nh gi√° t·ªët c√°c tr·∫°ng th√°i v√† l·ª±a ch·ªçn h√†nh ƒë·ªông t·ªëi ∆∞u trong h·∫ßu h·∫øt t√¨nh hu·ªëng. Th·ªùi gian trung b√¨nh m·ªói v√°n kho·∫£ng 0.097 gi√¢y, th·ªÉ hi·ªán r·∫±ng thu·∫≠t to√°n ƒë∆∞·ª£c tri·ªÉn khai hi·ªáu qu·∫£ ‚Äî c√¢n b·∫±ng t·ªët gi·ªØa ƒë·ªô s√¢u t√¨m ki·∫øm v√† t·ªëc ƒë·ªô x·ª≠ l√Ω. V·ªõi b√†n 2√ó2 √¥ (3√ó3 ƒëi·ªÉm), vi·ªác ƒë·∫°t hi·ªáu su·∫•t cao nh∆∞ v·∫≠y cho th·∫•y Minimax c√≥ th·ªÉ m√¥ h√¨nh h√≥a ƒë√∫ng chi·∫øn l∆∞·ª£c ‚ÄúƒÉn ƒëi·ªÉm an to√†n‚Äù v√† ‚Äútr√°nh m·ªü √¥ cho ƒë·ªëi th·ªß‚Äù, v·ªën l√† ƒë·∫∑c tr∆∞ng c·ªßa tr√≤ Dots and Boxes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AFDye9kIBvO"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search [30 points]\n",
        "\n",
        "### Heuristic evaluation function\n",
        "\n",
        "Define and implement a heuristic evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s834AsbUIBvO"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "\n",
        "# --- Heuristic evaluation ---\n",
        "def heuristic(board, player):\n",
        "    \"\"\"\n",
        "    Tr·∫£ v·ªÅ gi√° tr·ªã heuristic t·ª´ g√≥c nh√¨n c·ªßa player +1.\n",
        "    Gi√° tr·ªã d∆∞∆°ng c√≥ l·ª£i cho +1, √¢m c√≥ l·ª£i cho -1.\n",
        "\n",
        "    Th√¥ng s·ªë:\n",
        "      board: dict v·ªõi keys 'size', 'lines', 'boxes'\n",
        "      player: +1 ho·∫∑c -1 -> ng∆∞·ªùi ƒëang chu·∫©n b·ªã ƒëi\n",
        "\n",
        "    √ù t∆∞·ªüng:\n",
        "      - completed_score: ch√™nh l·ªách √¥ ƒë√£ ho√†n th√†nh (sum of box owners)\n",
        "      - count_3_sided: s·ªë √¥ hi·ªán c√≥ ƒë√∫ng 3 c·∫°nh (ng∆∞·ªùi ƒëi ti·∫øp c√≥ th·ªÉ ƒÉn ngay)\n",
        "      - count_2_sided: s·ªë √¥ c√≥ ƒë√∫ng 2 c·∫°nh (ti·ªÅm nƒÉng)\n",
        "      - Gi√° tr·ªã tr·∫£ v·ªÅ l√† k·∫øt h·ª£p tuy·∫øn t√≠nh c√°c y·∫øu t·ªë tr√™n.\n",
        "    \"\"\"\n",
        "    rows, cols = board['size']\n",
        "    completed_score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "\n",
        "    count_3 = 0\n",
        "    count_2 = 0\n",
        "\n",
        "    # duy·ªát m·ªçi √¥ (√¥ c√≥ top-left coord t·ª´ (0,0) t·ªõi (rows-2, cols-2))\n",
        "    for r in range(rows - 1):\n",
        "        for c in range(cols - 1):\n",
        "            if (r, c) in board['boxes']:\n",
        "                continue  # ƒë√£ ho√†n th√†nh\n",
        "            sides = 0\n",
        "            # top\n",
        "            if ('h', r, c) in board['lines']:\n",
        "                sides += 1\n",
        "            # bottom\n",
        "            if ('h', r + 1, c) in board['lines']:\n",
        "                sides += 1\n",
        "            # left\n",
        "            if ('v', r, c) in board['lines']:\n",
        "                sides += 1\n",
        "            # right\n",
        "            if ('v', r, c + 1) in board['lines']:\n",
        "                sides += 1\n",
        "\n",
        "            if sides == 3:\n",
        "                count_3 += 1\n",
        "            elif sides == 2:\n",
        "                count_2 += 1\n",
        "\n",
        "    # tr·ªçng s·ªë (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)\n",
        "    w3 = 1.0   # 3-sided box ~ 1 point immediate\n",
        "    w2 = 0.3   # 2-sided box potential\n",
        "\n",
        "    # count_3 l√† c∆° h·ªôi cho ng∆∞·ªùi **s·∫Øp ƒëi** -> nh√¢n v·ªõi player ƒë·ªÉ ƒë·∫∑t v·ªÅ g√≥c nh√¨n +1\n",
        "    value = completed_score + w3 * (count_3 * player) + w2 * (count_2 * player)\n",
        "    return value\n",
        "\n",
        "\n",
        "# --- C·∫≠p nh·∫≠t minimax_search ƒë·ªÉ d√πng heuristic khi depth == 0 ---\n",
        "def minimax_search(board, player, depth, alpha, beta):\n",
        "    \"\"\"\n",
        "    Minimax + alpha-beta. Khi depth == 0 (leaf), d√πng heuristic(board, player).\n",
        "    Tr·∫£ v·ªÅ gi√° tr·ªã theo g√≥c nh√¨n c·ªßa +1 (d∆∞∆°ng = t·ªët cho +1).\n",
        "    \"\"\"\n",
        "    if terminal(board):\n",
        "        return utility(board)\n",
        "\n",
        "    if depth == 0:\n",
        "        return heuristic(board, player)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_search(new_board, next_player, depth - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAZSVupr4tN_",
        "outputId": "30be8bc3-d237-42f5-b3e9-23a52d56bd8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "board1 heuristic (player=+1): 0.0\n",
            "board1 heuristic (player=-1): 0.0\n",
            "board2 heuristic (player=+1): 1.0\n",
            "board2 heuristic (player=-1): -1.0\n",
            "board3 heuristic (player=+1): 1.3\n"
          ]
        }
      ],
      "source": [
        "# v√≠ d·ª• 1: board tr·ªëng 3x3 ƒëi·ªÉm (2x2 boxes)\n",
        "board1 = {'size': (3,3), 'lines': {}, 'boxes': {}}\n",
        "print(\"board1 heuristic (player=+1):\", heuristic(board1, +1))\n",
        "print(\"board1 heuristic (player=-1):\", heuristic(board1, -1))\n",
        "\n",
        "# v√≠ d·ª• 2: m·ªôt √¥ c√≥ 3 c·∫°nh (ng∆∞·ªùi ƒëi c√≥ th·ªÉ ƒÉn)\n",
        "board2 = {'size': (3,3),\n",
        "          'lines': {('h',0,0):True, ('v',0,0):True, ('h',1,0):True}, # √¥ (0,0) c√≥ 3 c·∫°nh\n",
        "          'boxes': {}}\n",
        "print(\"board2 heuristic (player=+1):\", heuristic(board2, +1))\n",
        "print(\"board2 heuristic (player=-1):\", heuristic(board2, -1))\n",
        "\n",
        "# v√≠ d·ª• 3: m·ªôt v√†i c·∫°nh kh√°c\n",
        "board3 = {'size': (4,4),\n",
        "          'lines': {('h',0,0):True, ('v',0,0):True, ('v',0,1):True, ('h',1,1):True},\n",
        "          'boxes': {}}\n",
        "print(\"board3 heuristic (player=+1):\", heuristic(board3, +1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58c1TLHlKPUn"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "H√†m heuristic ho·∫°t ƒë·ªông ƒë√∫ng v√† h·ª£p l√Ω: v·ªõi b√†n tr·ªëng gi√° tr·ªã 0 cho th·∫•y th·∫ø c√¢n b·∫±ng; v·ªõi √¥ c√≥ 3 c·∫°nh, ng∆∞·ªùi s·∫Øp ƒëi (+1) ƒë∆∞·ª£c l·ª£i th·∫ø (+1.0) c√≤n ƒë·ªëi th·ªß b·∫•t l·ª£i (-1.0); v·ªõi b√†n c√≥ √¥ 2 c·∫°nh, gi√° tr·ªã 1.3 ph·∫£n √°nh ti·ªÅm nƒÉng ghi ƒëi·ªÉm. Tr·ªçng s·ªë w3=1.0 v√† w2=0.3 gi√∫p m√¥ h√¨nh ∆∞u ti√™n ƒÉn ƒëi·ªÉm tr∆∞·ªõc nh∆∞ng v·∫´n xem x√©t c∆° h·ªôi ph√°t tri·ªÉn. H√†m ph√π h·ª£p ƒë·ªÉ t√≠ch h·ª£p v√†o Minimax, th·ªÉ hi·ªán ƒë√°nh gi√° chi·∫øn l∆∞·ª£c t·ªët v√† logic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhkT8bF4IBvO"
      },
      "source": [
        "### Cutting off search\n",
        "\n",
        "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWZPLRZsIBvP"
      },
      "outputs": [],
      "source": [
        "def minimax_cutoff(board, player, depth_limit, alpha=-math.inf, beta=math.inf):\n",
        "    \"\"\"\n",
        "    Minimax v·ªõi c·∫Øt ƒë·ªô s√¢u (cutoff) + alpha-beta pruning.\n",
        "    \"\"\"\n",
        "    if terminal(board):\n",
        "        return utility(board)\n",
        "    if depth_limit == 0:\n",
        "        return heuristic(board, player)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_cutoff(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_cutoff(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOxUh9j37k6Q",
        "outputId": "6d714c5a-2516-4d60-f56d-d9e7d2a717aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth= 1 -> Value=  0.00, Time=0.0002s\n",
            "Depth= 2 -> Value=  0.00, Time=0.0005s\n",
            "Depth= 3 -> Value= -0.30, Time=0.0050s\n",
            "Depth= 4 -> Value=  0.60, Time=0.0127s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "board = {'size': (3,3), 'lines': {}, 'boxes': {}}  # b·∫£ng 2x2 boxes\n",
        "for depth in [1, 2, 3, 4]:\n",
        "    t0 = time.time()\n",
        "    val = minimax_cutoff(board, player=+1, depth_limit=depth)\n",
        "    t1 = time.time()\n",
        "    print(f\"Depth={depth:2d} -> Value={val:6.2f}, Time={(t1-t0):.4f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGafDehNJAH"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ cho th·∫•y khi tƒÉng ƒë·ªô s√¢u, gi√° tr·ªã ƒë√°nh gi√° thay ƒë·ªïi r√µ r·ªát: ·ªü ƒë·ªô s√¢u nh·ªè (1‚Äì2) gi√° tr·ªã g·∫ßn 0 th·ªÉ hi·ªán th·∫ø c√¢n b·∫±ng v√¨ ch∆∞a ƒë·ªß th√¥ng tin; ·ªü depth=3 gi√° tr·ªã √¢m (-0.30) cho th·∫•y ng∆∞·ªùi ch∆°i +1 c√≥ th·ªÉ r∆°i v√†o t√¨nh hu·ªëng b·∫•t l·ª£i t·∫°m th·ªùi; nh∆∞ng ƒë·∫øn depth=4 gi√° tr·ªã d∆∞∆°ng (0.60) ch·ª©ng t·ªè khi xem x√©t xa h∆°n, ng∆∞·ªùi ch∆°i +1 c√≥ chi·∫øn l∆∞·ª£c t·ªët h∆°n. Th·ªùi gian tƒÉng d·∫ßn theo ƒë·ªô s√¢u (0.0002s ‚Üí 0.0127s) ph·∫£n √°nh ƒë√∫ng ƒë·∫∑c tr∆∞ng c·ªßa Minimax c√≥ c·∫Øt ƒë·ªô s√¢u v√† alpha-beta pruning, ho·∫°t ƒë·ªông hi·ªáu qu·∫£ v√† h·ª£p l√Ω."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTp4i0e9IBvP"
      },
      "outputs": [],
      "source": [
        "node_counter = 0\n",
        "\n",
        "def minimax_count(board, player, depth_limit, alpha=-math.inf, beta=math.inf):\n",
        "    global node_counter\n",
        "    node_counter += 1\n",
        "\n",
        "    if terminal(board):\n",
        "        return sum(board['boxes'].values())\n",
        "    if depth_limit == 0:\n",
        "        return heuristic(board, player)\n",
        "\n",
        "    if player == +1:\n",
        "        value = -math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = max(value, minimax_count(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta: break\n",
        "        return value\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for action in actions(board):\n",
        "            new_board, next_player = result(board, action, player)\n",
        "            value = min(value, minimax_count(new_board, next_player, depth_limit - 1, alpha, beta))\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta: break\n",
        "        return value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuXGHCe9TUD",
        "outputId": "11edb63d-09ae-4301-9920-db22be99d815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Board: 3x4, Nodes searched: 54, Time: 0.0012s, Value=0.00\n",
            "Board: 3x5, Nodes searched: 69, Time: 0.0020s, Value=0.00\n",
            "Board: 3x6, Nodes searched: 84, Time: 0.0016s, Value=0.00\n"
          ]
        }
      ],
      "source": [
        "for cols in [4, 5, 6]:\n",
        "    board = {'size': (3, cols), 'lines': {}, 'boxes': {}}\n",
        "    node_counter = 0\n",
        "    t0 = time.time()\n",
        "    value = minimax_count(board, player=+1, depth_limit=2)  # depth c·ªë ƒë·ªãnh\n",
        "    t1 = time.time()\n",
        "    print(f\"Board: 3x{cols}, Nodes searched: {node_counter}, Time: {t1-t0:.4f}s, Value={value:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdH9znN_NYKR"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "Khi k√≠ch th∆∞·ªõc b√†n tƒÉng t·ª´ 3x4 ‚Üí 3x6, s·ªë n√∫t ƒë∆∞·ª£c duy·ªát tƒÉng d·∫ßn (54 ‚Üí 69 ‚Üí 84), ch·ª©ng t·ªè kh√¥ng gian t√¨m ki·∫øm m·ªü r·ªông theo s·ªë c·∫°nh c√≥ th·ªÉ ƒëi, ƒë√∫ng v·ªõi b·∫£n ch·∫•t c·ªßa Minimax. Th·ªùi gian x·ª≠ l√Ω c≈©ng tƒÉng nh·∫π nh∆∞ng v·∫´n trong m·ª©c r·∫•t nhanh, cho th·∫•y thu·∫≠t to√°n ho·∫°t ƒë·ªông hi·ªáu qu·∫£ ·ªü ƒë·ªô s√¢u 2. Gi√° tr·ªã ƒë√°nh gi√° ƒë·ªÅu b·∫±ng 0.00 th·ªÉ hi·ªán b√†n c√≤n tr·ªëng, ch∆∞a c√≥ t√¨nh hu·ªëng l·ª£i th·∫ø r√µ r√†ng cho b√™n n√†o. Nh√¨n chung, h√†m ƒë·∫øm n√∫t ho·∫°t ƒë·ªông ch√≠nh x√°c, ph·∫£n √°nh ƒë√∫ng xu h∆∞·ªõng tƒÉng ƒë·ªô ph·ª©c t·∫°p khi k√≠ch th∆∞·ªõc b√†n l·ªõn h∆°n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtjP48mxIBvP"
      },
      "source": [
        "### Playtime\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo4WxEzyIBvP"
      },
      "outputs": [],
      "source": [
        "import copy, math, time\n",
        "\n",
        "# --- Heuristic functions ---\n",
        "def heuristic1(board, player):\n",
        "    # ƒë∆°n gi·∫£n: ch·ªâ ƒë·∫øm √¥ ho√†n th√†nh\n",
        "    return sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "\n",
        "def heuristic2(board, player):\n",
        "    # n√¢ng cao: ƒë·∫øm √¥ + tr·ªçng s·ªë c√°c √¥ c√≥ 3 c·∫°nh\n",
        "    rows, cols = board['size']\n",
        "    score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "    for r in range(rows-1):\n",
        "        for c in range(cols-1):\n",
        "            if (r, c) in board['boxes']: continue\n",
        "            sides = 0\n",
        "            if ('h', r, c) in board['lines']: sides += 1\n",
        "            if ('h', r+1, c) in board['lines']: sides += 1\n",
        "            if ('v', r, c) in board['lines']: sides += 1\n",
        "            if ('v', r, c+1) in board['lines']: sides += 1\n",
        "            if sides == 3: score += 0.5  # tr·ªçng s·ªë\n",
        "    return score\n",
        "\n",
        "def heuristic_agent(board, player, depth, heuristic):\n",
        "    best_score = -math.inf if player==+1 else math.inf\n",
        "    best_action = None\n",
        "    for action in actions(board):\n",
        "        nb, np_next = result(board, action, player)\n",
        "        score = minimax_cutoff(nb, np_next, depth-1, heuristic)\n",
        "        if player == +1 and score > best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "        elif player == -1 and score < best_score:\n",
        "            best_score = score\n",
        "            best_action = action\n",
        "    return best_action\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT6l2VbJASte",
        "outputId": "4812b42c-f95b-4a99-f443-7893d37e8550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B√†n cu·ªëi: {'size': (4, 4), 'lines': {('h', 0, 0): True, ('h', 0, 1): True, ('h', 0, 2): True, ('h', 1, 0): True, ('h', 1, 1): True, ('h', 1, 2): True, ('h', 2, 0): True, ('h', 2, 1): True, ('h', 2, 2): True, ('h', 3, 1): True, ('h', 3, 0): True, ('h', 3, 2): True, ('v', 0, 0): True, ('v', 0, 1): True, ('v', 0, 2): True, ('v', 0, 3): True, ('v', 1, 0): True, ('v', 1, 1): True, ('v', 1, 2): True, ('v', 1, 3): True, ('v', 2, 0): True, ('v', 2, 1): True, ('v', 2, 2): True, ('v', 2, 3): True}, 'boxes': {(0, 0): -1, (0, 1): -1, (0, 2): -1, (1, 0): 1, (1, 1): 1, (1, 2): 1, (2, 0): -1, (2, 1): -1, (2, 2): -1}}\n",
            "T·ªïng ƒëi·ªÉm +1: 3\n",
            "T·ªïng ƒëi·ªÉm -1: -6\n",
            "Ng∆∞·ªùi ch∆°i -1 th·∫Øng!\n"
          ]
        }
      ],
      "source": [
        "# --- Play one game ---\n",
        "def play_heuristic_agents(depth1=2, depth2=3):\n",
        "    board = {'size': (4,4), 'lines': {}, 'boxes': {}}\n",
        "    player = +1\n",
        "    while not terminal(board):\n",
        "        if player == +1:\n",
        "            action = heuristic_agent(board, player, depth1, heuristic1)\n",
        "        else:\n",
        "            action = heuristic_agent(board, player, depth2, heuristic2)\n",
        "        if action is None:\n",
        "            break\n",
        "        board, player = result(board, action, player)\n",
        "    final_score = sum(board['boxes'].values()) if board['boxes'] else 0\n",
        "    print(\"B√†n cu·ªëi:\", board)\n",
        "    print(\"T·ªïng ƒëi·ªÉm +1:\", sum([v for v in board['boxes'].values() if v==+1]))\n",
        "    print(\"T·ªïng ƒëi·ªÉm -1:\", sum([v for v in board['boxes'].values() if v==-1]))\n",
        "    if final_score > 0:\n",
        "        print(\"Ng∆∞·ªùi ch∆°i +1 th·∫Øng!\")\n",
        "    elif final_score < 0:\n",
        "        print(\"Ng∆∞·ªùi ch∆°i -1 th·∫Øng!\")\n",
        "    else:\n",
        "        print(\"H√≤a!\")\n",
        "\n",
        "play_heuristic_agents()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfbRYYRLOB51"
      },
      "source": [
        "Nh·∫≠n x√©t:\n",
        "\n",
        "K·∫øt qu·∫£ cho th·∫•y v·ªõi c√πng b√†n 4√ó4, ng∆∞·ªùi ch∆°i d√πng heuristic2 (c√≥ tr·ªçng s·ªë cho c√°c √¥ c√≥ 3 c·∫°nh) th·∫Øng r√µ r·ªát tr∆∞·ªõc ng∆∞·ªùi d√πng heuristic1 (ch·ªâ t√≠nh √¥ ho√†n th√†nh). C·ª• th·ªÉ, ng∆∞·ªùi ch∆°i ‚àí1 ghi ƒë∆∞·ª£c 6 √¥ so v·ªõi 3 √¥ c·ªßa +1. ƒêi·ªÅu n√†y ch·ª©ng minh r·∫±ng heuristic2 c√≥ kh·∫£ nƒÉng ƒë√°nh gi√° v·ªã th·∫ø ch√≠nh x√°c v√† chi·∫øn l∆∞·ª£c h∆°n, gi√∫p ch·ªçn c√°c n∆∞·ªõc ƒëi ti·ªÅm nƒÉng t·∫°o l·ª£i th·∫ø d√†i h·∫°n thay v√¨ ch·ªâ ph·∫£n ·ª©ng theo ƒëi·ªÉm hi·ªán t·∫°i. K·∫øt qu·∫£ ph·∫£n √°nh hi·ªáu qu·∫£ c·ªßa vi·ªác th√™m y·∫øu t·ªë ‚Äú√¥ c√≥ 3 c·∫°nh‚Äù trong ƒë√°nh gi√°, gi√∫p thu·∫≠t to√°n d·ª± ƒëo√°n t·ªët h∆°n c√°c c∆° h·ªôi ƒÉn ƒëi·ªÉm trong t∆∞∆°ng lai."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
